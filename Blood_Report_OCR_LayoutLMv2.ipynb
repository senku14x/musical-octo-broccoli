{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab59ec08",
   "metadata": {},
   "source": [
    "# ðŸš€ Blood Report OCR + LayoutLMv2 Processing Pipeline\n",
    "This notebook extracts text from blood test reports using OCR, cleans and processes the text, applies LayoutLMv2 for structured entity extraction, and saves the results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35231e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!apt-get install -y tesseract-ocr\n",
    "!pip install pytesseract pdf2image\n",
    "!pip install --upgrade torch torchvision torchaudio transformers datasets seqeval pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9ca13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import cv2\n",
    "import torch\n",
    "import shutil\n",
    "import csv\n",
    "from PIL import Image, ImageDraw\n",
    "from pdf2image import convert_from_path\n",
    "from datasets import Dataset\n",
    "from transformers import LayoutLMv2Processor, LayoutLMv2ForTokenClassification, TrainingArguments, Trainer\n",
    "from google.colab import files\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()  # Initialize Faker for random names\n",
    "\n",
    "# If using Windows, set Tesseract path (update based on installation)\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a686e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocesses image for better OCR accuracy: Resize, Binarize, Denoise.\"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (1000, 1000))  # Resize for uniformity\n",
    "    image = cv2.GaussianBlur(image, (5, 5), 0)  # Reduce noise\n",
    "    _, image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)  # Convert to binary\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d836b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_image(image_path):\n",
    "    \"\"\"Extracts text from a blood report image using Tesseract OCR.\"\"\"\n",
    "    processed_image = preprocess_image(image_path)\n",
    "    extracted_text = pytesseract.image_to_string(processed_image, config=\"--psm 6\")\n",
    "    return extracted_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167abb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_patient_name(text):\n",
    "    \"\"\"Standardizes 'Patient Name', 'Name', and similar fields.\"\"\"\n",
    "    name_variants = [\"Patient Name\", \"Name\", \"Full Name\", \"Pt. Name\", \"Patient's Name\"]\n",
    "    \n",
    "    for variant in name_variants:\n",
    "        if variant in text:\n",
    "            text = text.replace(variant, \"Patient Name\")\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc28279",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_lab_parameters(text):\n",
    "    \"\"\"Extracts lab parameter values from OCR text and fixes common OCR misreadings.\"\"\"\n",
    "    parameters = {\n",
    "        \"Hemoglobin\": r\"Hemoglobin[:\\s]*([\\d.]+)\\s*(g/dL|g/dL)?\",\n",
    "        \"RBC\": r\"RBC[:\\s]*([\\d.]+)\\s*(million/cmm|million/?cmm)?\",\n",
    "        \"PCV\": r\"PCV[:\\s]*([\\d.]+)\\s*(%)?\",\n",
    "        \"MCV\": r\"MCV[:\\s]*([\\d.]+)\\s*(fL|fl)?\",\n",
    "        \"MCH\": r\"MCH[:\\s]*([\\d.]+)\\s*(pg|Pg)?\",\n",
    "        \"MCHC\": r\"MCHC[:\\s]*([\\d.]+)\\s*(g/dL|gdl)?\",\n",
    "        \"RDW\": r\"RDW[:\\s]*([\\d.]+)\\s*(%)?\",\n",
    "        \"WBC\": r\"WBC[:\\s]*([\\d,]+)\\s*(/cmm|cmm)?\",\n",
    "        \"Neutrophils\": r\"Neutrophils[:\\s]*([\\d.]+)\\s*(%)?\",\n",
    "        \"Lymphocytes\": r\"Lymphocytes[:\\s]*([\\d.]+)\\s*(%)?\",\n",
    "        \"Eosinophils\": r\"Eosinophils[:\\s]*([\\d.]+)\\s*(%)?\",\n",
    "        \"Monocytes\": r\"Monocytes[:\\s]*([\\d.]+)\\s*(%)?\",\n",
    "        \"Basophils\": r\"Basophils[:\\s]*([\\d.]+)\\s*(%)?\",\n",
    "        \"Platelets\": r\"Platelets[:\\s]*([\\d,]+)\\s*(x10\\^3/cmm|platelets)?\"\n",
    "    }\n",
    "\n",
    "    extracted_values = {}\n",
    "    for param, pattern in parameters.items():\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            value = match.group(1).replace(\",\", \"\").replace(\"O\", \"0\").replace(\"l\", \"1\")  \n",
    "            extracted_values[param] = float(value) if \".\" in value else int(value)\n",
    "\n",
    "    return extracted_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fec5758",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_medical_report(image_path, model, processor):\n",
    "    \"\"\"Extracts text, normalizes fields, extracts lab values, and processes via LayoutLMv2.\"\"\"\n",
    "    \n",
    "    extracted_text = extract_text_from_image(image_path)\n",
    "    extracted_text = normalize_patient_name(extracted_text)\n",
    "\n",
    "    # Extract patient name\n",
    "    match = re.search(r\"Patient Name[:\\s]*([A-Za-z\\s]+)\", extracted_text)\n",
    "    patient_name = match.group(1).strip() if match else \"Unknown\"\n",
    "\n",
    "    # Extract lab values\n",
    "    lab_values = extract_lab_parameters(extracted_text)\n",
    "\n",
    "    # Process with LayoutLMv2\n",
    "    encoding = processor(\n",
    "        images=[Image.open(image_path).convert(\"RGB\")],\n",
    "        text=[list(extracted_text.split())],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**encoding)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predicted_ids = logits.argmax(dim=2).squeeze().tolist()\n",
    "\n",
    "    return {\n",
    "        \"Patient Name\": patient_name,\n",
    "        **lab_values\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb4e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_to_csv(data, output_filepath):\n",
    "    \"\"\"Saves OCR extracted data + LayoutLMv2 structured results to CSV and provides download link.\"\"\"\n",
    "    with open(output_filepath, \"w\", newline=\"\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Patient Name\", \"Parameter\", \"Value\"])\n",
    "        patient_name = data.pop(\"Patient Name\", \"Unknown\")\n",
    "\n",
    "        for param, value in data.items():\n",
    "            writer.writerow([patient_name, param, value])\n",
    "\n",
    "    print(f\"âœ… Saved results to: {output_filepath}\")\n",
    "    files.download(output_filepath)  # Auto-download in Google Colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a91605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_image_path = \"./sample_report.png\"\n",
    "output_csv = \"extracted_blood_report.csv\"\n",
    "\n",
    "ocr_result = process_medical_report(test_image_path, model, processor)\n",
    "save_to_csv(ocr_result, output_csv)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
