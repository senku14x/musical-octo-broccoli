{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 172358,
     "status": "ok",
     "timestamp": 1736570616645,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "2XiGWiLSy_9v",
    "outputId": "82480678-fab8-4be9-b188-426bf8abcaf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Collecting pymupdf\n",
      "  Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pymupdf-1.25.1-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.25.1\n",
      "📤 Upload the 'Publishable' PDF Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-d7fe1aef-5edd-4260-99f0-30b2d310e478\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-d7fe1aef-5edd-4260-99f0-30b2d310e478\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving R006.pdf to R006.pdf\n",
      "Saving R007.pdf to R007.pdf\n",
      "Saving R008.pdf to R008.pdf\n",
      "Saving R009.pdf to R009.pdf\n",
      "Saving R010.pdf to R010.pdf\n",
      "Saving R011.pdf to R011.pdf\n",
      "Saving R012.pdf to R012.pdf\n",
      "Saving R013.pdf to R013.pdf\n",
      "Saving R014.pdf to R014.pdf\n",
      "Saving R015.pdf to R015.pdf\n",
      "\n",
      "📤 Upload the 'Non-Publishable' PDF Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-509f6438-5ef0-4836-aa18-575d830e6f05\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-509f6438-5ef0-4836-aa18-575d830e6f05\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving R001.pdf to R001.pdf\n",
      "Saving R002.pdf to R002.pdf\n",
      "Saving R003.pdf to R003.pdf\n",
      "Saving R004.pdf to R004.pdf\n",
      "Saving R005.pdf to R005.pdf\n",
      "✅ Combined training dataset saved to /content/merged_training_dataset.csv\n",
      "\n",
      "📝 Combined Training Dataset Overview (First 5 rows):\n",
      "   filename                                            content        label\n",
      "0  R006.pdf  Detailed Action Identification in Baseball Gam...  Publishable\n",
      "1  R007.pdf  Advancements in 3D Food Modeling: A Review of ...  Publishable\n",
      "2  R008.pdf  Advanced techniques for through and contextual...  Publishable\n",
      "3  R009.pdf  The Importance of Written Explanations in\\nAgg...  Publishable\n",
      "4  R010.pdf  Detecting Medication Usage in Parkinson’s Dise...  Publishable\n",
      "\n",
      "📥 Click below to download the merged training dataset:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_b548a7be-3600-4b1b-b7fd-84d53f87de43\", \"merged_training_dataset.csv\", 549294)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Upload and Convert PDF Datasets in Colab\n",
    "# Install necessary modules\n",
    "!pip install pandas pymupdf\n",
    "\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF for PDF text extraction\n",
    "\n",
    "# 📤 Upload 'Publishable' PDF Dataset\n",
    "print(\"📤 Upload the 'Publishable' PDF Dataset:\")\n",
    "uploaded_publishable = files.upload()\n",
    "publishable_pdf_files = list(uploaded_publishable.keys())\n",
    "\n",
    "# 📤 Upload 'Non-Publishable' PDF Dataset\n",
    "print(\"\\n📤 Upload the 'Non-Publishable' PDF Dataset:\")\n",
    "uploaded_non_publishable = files.upload()\n",
    "non_publishable_pdf_files = list(uploaded_non_publishable.keys())\n",
    "\n",
    "# Function to extract text from PDFs\n",
    "def extract_text_from_pdfs(pdf_files):\n",
    "    extracted_data = []\n",
    "    for pdf_file in pdf_files:\n",
    "        doc = fitz.open(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        extracted_data.append({\"filename\": pdf_file, \"content\": text})\n",
    "    return extracted_data\n",
    "\n",
    "# Extract text from 'Publishable' PDFs\n",
    "publishable_data = extract_text_from_pdfs(publishable_pdf_files)\n",
    "df_publishable = pd.DataFrame(publishable_data)\n",
    "df_publishable['label'] = 'Publishable'\n",
    "\n",
    "# Extract text from 'Non-Publishable' PDFs\n",
    "non_publishable_data = extract_text_from_pdfs(non_publishable_pdf_files)\n",
    "df_non_publishable = pd.DataFrame(non_publishable_data)\n",
    "df_non_publishable['label'] = 'Non-Publishable'\n",
    "\n",
    "# Combine Publishable and Non-Publishable datasets\n",
    "df_train = pd.concat([df_publishable, df_non_publishable], ignore_index=True)\n",
    "\n",
    "# Save as CSV\n",
    "merged_csv_path = '/content/merged_training_dataset.csv'\n",
    "df_train.to_csv(merged_csv_path, index=False)\n",
    "print(f\"✅ Combined training dataset saved to {merged_csv_path}\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"\\n📝 Combined Training Dataset Overview (First 5 rows):\")\n",
    "print(df_train.head())\n",
    "\n",
    "# Enable download of the merged dataset\n",
    "from google.colab import files\n",
    "\n",
    "print(\"\\n📥 Click below to download the merged training dataset:\")\n",
    "files.download(merged_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_G5jSnkyz25l"
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install pandas nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VKxUk0iEz4jT"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries for preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"  # Handle NaN entries gracefully\n",
    "\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Remove stopwords\n",
    "    text = ' '.join(word for word in text.split() if word not in stop_words)\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply text preprocessing\n",
    "df_train['content'] = df_train['content'].apply(preprocess_text)\n",
    "\n",
    "# Handle missing values\n",
    "df_train.dropna(subset=['content', 'label'], inplace=True)\n",
    "\n",
    "print(\"\\n✅ Text Preprocessing Completed.\")\n",
    "print(\"\\n📝 First 5 rows after preprocessing:\")\n",
    "print(df_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "km7B9LTE0DjP"
   },
   "outputs": [],
   "source": [
    "# Save the preprocessed dataset\n",
    "preprocessed_csv_path = '/content/preprocessed_training_dataset.csv'\n",
    "df_train.to_csv(preprocessed_csv_path, index=False)\n",
    "print(f\"✅ Preprocessed training dataset saved to {preprocessed_csv_path}\")\n",
    "\n",
    "# Enable download of the preprocessed dataset\n",
    "from google.colab import files\n",
    "\n",
    "print(\"\\n📥 Click below to download the preprocessed training dataset:\")\n",
    "files.download(preprocessed_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6228,
     "status": "ok",
     "timestamp": 1736056068434,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "4FsFXDKo0J2o",
    "outputId": "fd321c3b-c317-4bac-97ff-5bb6bf7365c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages\n",
    "!pip install transformers pandas torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "tk7bwQYX0xNG"
   },
   "outputs": [],
   "source": [
    "# Step 3: Feature Engineering with BERT Embeddings\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load preprocessed dataset\n",
    "preprocessed_csv_path = '/content/preprocessed_training_dataset.csv'\n",
    "df_train = pd.read_csv(preprocessed_csv_path)\n",
    "\n",
    "# Verify dataset structure\n",
    "print(\"\\n✅ Dataset loaded for Feature Engineering with BERT.\")\n",
    "print(\"\\n📝 First 5 rows of the dataset:\")\n",
    "print(df_train.head())\n",
    "\n",
    "# Check for required columns\n",
    "if 'content' not in df_train.columns or 'label' not in df_train.columns:\n",
    "    raise ValueError(\"Dataset must have 'content' and 'label' columns!\")\n",
    "\n",
    "# Encode labels\n",
    "df_train['label'] = df_train['label'].map({'Publishable': 1, 'Non-Publishable': 0})\n",
    "\n",
    "# ✅ Load BERT Model and Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(f\"\\n✅ Using device: {device}\")\n",
    "\n",
    "# ✅ Function to extract BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.pooler_output.squeeze().cpu().numpy()\n",
    "\n",
    "# Apply BERT embeddings to the dataset\n",
    "print(\"\\n⚙️ Generating BERT embeddings (this may take time)...\")\n",
    "bert_embeddings = df_train['content'].apply(get_bert_embedding)\n",
    "\n",
    "# Convert embeddings to a feature matrix\n",
    "X = torch.stack([torch.tensor(embed) for embed in bert_embeddings]).numpy()\n",
    "y = df_train['label'].values\n",
    "\n",
    "print(\"\\n✅ BERT embeddings successfully generated.\")\n",
    "print(f\"Feature Matrix Shape: {X.shape}\")\n",
    "\n",
    "# ✅ Split Dataset into Training and Validation Sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Dataset Split:\")\n",
    "print(f\"Training Set: {X_train.shape}\")\n",
    "print(f\"Validation Set: {X_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "F5GRGUQu08yg"
   },
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "8-7OQAWR1PS4"
   },
   "outputs": [],
   "source": [
    "# Step 4: Train Transformer-Based Model for Publishability Classification\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Load Preprocessed Dataset\n",
    "preprocessed_csv_path = '/content/preprocessed_training_dataset.csv'\n",
    "df_train = pd.read_csv(preprocessed_csv_path)\n",
    "\n",
    "# Verify dataset structure\n",
    "print(\"\\n✅ Dataset loaded for Transformer-based Training.\")\n",
    "print(df_train.head())\n",
    "\n",
    "# ✅ Encode Labels\n",
    "df_train['label'] = df_train['label'].map({'Publishable': 1, 'Non-Publishable': 0})\n",
    "\n",
    "# ✅ Split Data into Training and Validation Sets\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df_train['content'].tolist(),\n",
    "    df_train['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df_train['label']\n",
    ")\n",
    "\n",
    "# ✅ Tokenize Data for BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_encodings = tokenizer(\n",
    "    train_texts, truncation=True, padding=True, max_length=512, return_tensors='pt'\n",
    ")\n",
    "val_encodings = tokenizer(\n",
    "    val_texts, truncation=True, padding=True, max_length=512, return_tensors='pt'\n",
    ")\n",
    "\n",
    "# ✅ Create a Custom Dataset Class\n",
    "class PublishabilityDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = PublishabilityDataset(train_encodings, train_labels)\n",
    "val_dataset = PublishabilityDataset(val_encodings, val_labels)\n",
    "\n",
    "# ✅ Load Pre-trained Transformer Model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "print(f\"\\n✅ Using device: {device}\")\n",
    "\n",
    "# ✅ Define Optimizer and Scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# ✅ Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# ✅ Training Loop\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, train_loader, val_loader, optimizer, device, epochs=12):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\n🔄 Epoch {epoch + 1}/{epochs}')\n",
    "        loop = tqdm(train_loader, leave=True)\n",
    "        for batch in loop:\n",
    "            optimizer.zero_grad()\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loop.set_description(f'Epoch {epoch + 1}')\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "# ✅ Start Training\n",
    "train_model(model, train_loader, val_loader, optimizer, device)\n",
    "\n",
    "# ✅ Evaluation Loop\n",
    "def evaluate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "\n",
    "    print(\"\\n📊 Evaluation Metrics:\")\n",
    "    print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "    print(f\"✅ F1-Score: {f1:.4f}\")\n",
    "    print(f\"✅ Precision: {precision:.4f}\")\n",
    "    print(f\"✅ Recall: {recall:.4f}\")\n",
    "\n",
    "# ✅ Evaluate the Model\n",
    "evaluate_model(model, val_loader, device)\n",
    "\n",
    "# ✅ Save the Trained Model\n",
    "model_save_path = '/content/publishability_transformer_model.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"\\n✅ Transformer model saved to {model_save_path}\")\n",
    "\n",
    "# ✅ Download the Model\n",
    "from google.colab import files\n",
    "\n",
    "print(\"\\n📥 Click below to download the trained Transformer model:\")\n",
    "files.download(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "zYRQoZXm10TX"
   },
   "outputs": [],
   "source": [
    "# Step 5: Evaluate Transformer Model on Validation Set\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# ✅ Load Validation Dataset\n",
    "print(\"\\n✅ Using the prepared validation dataset for evaluation.\")\n",
    "print(f\"Validation Set Size: {len(val_loader)} batches\")\n",
    "\n",
    "# ✅ Evaluation Function\n",
    "def evaluate_model_on_validation(model, val_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    print(\"\\n📊 Evaluation Metrics on Validation Set:\")\n",
    "    print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "    print(f\"✅ F1-Score: {f1:.4f}\")\n",
    "    print(f\"✅ Precision: {precision:.4f}\")\n",
    "    print(f\"✅ Recall: {recall:.4f}\")\n",
    "    print(\"\\n📊 Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Return predictions and true labels for analysis\n",
    "    return predictions, true_labels\n",
    "\n",
    "# ✅ Evaluate the Model\n",
    "val_predictions, val_true_labels = evaluate_model_on_validation(model, val_loader, device)\n",
    "\n",
    "# ✅ Save Validation Results for Further Analysis\n",
    "val_results_df = pd.DataFrame({\n",
    "    'True_Label': val_true_labels,\n",
    "    'Predicted_Label': val_predictions\n",
    "})\n",
    "\n",
    "validation_results_path = '/content/validation_results.csv'\n",
    "val_results_df.to_csv(validation_results_path, index=False)\n",
    "print(f\"\\n✅ Validation results saved to {validation_results_path}\")\n",
    "\n",
    "# ✅ Enable Download\n",
    "from google.colab import files\n",
    "\n",
    "print(\"\\n📥 Click below to download the validation results CSV:\")\n",
    "files.download(validation_results_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "HQc40D4a2kTW"
   },
   "outputs": [],
   "source": [
    "# Step 6: Upload and Convert PDF Test Dataset\n",
    "\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF for PDF text extraction\n",
    "\n",
    "# 📤 Upload PDF Test Dataset\n",
    "print(\"📤 Upload the Test PDFs (one or multiple files):\")\n",
    "uploaded_test_pdfs = files.upload()\n",
    "pdf_files = list(uploaded_test_pdfs.keys())\n",
    "\n",
    "# ✅ Extract Text from PDFs\n",
    "def extract_text_from_pdfs(pdf_files):\n",
    "    extracted_data = []\n",
    "    for i, pdf_file in enumerate(pdf_files):\n",
    "        doc = fitz.open(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        extracted_data.append({\"paper_id\": f\"paper_{i+1}\", \"content\": text})\n",
    "    return extracted_data\n",
    "\n",
    "# Extract text from PDFs\n",
    "test_data = extract_text_from_pdfs(pdf_files)\n",
    "df_test = pd.DataFrame(test_data)\n",
    "\n",
    "# Display extracted data\n",
    "print(\"\\n✅ Extracted text from PDFs. Sample DataFrame:\")\n",
    "print(df_test.head())\n",
    "\n",
    "# ✅ Save as CSV\n",
    "test_csv_path = '/content/test_dataset.csv'\n",
    "df_test.to_csv(test_csv_path, index=False,escapechar='\\\\')\n",
    "print(f\"\\n✅ Test dataset saved to {test_csv_path}\")\n",
    "\n",
    "# ✅ Enable Download\n",
    "from google.colab import files\n",
    "\n",
    "print(\"\\n📥 Click below to download the test dataset CSV:\")\n",
    "files.download(test_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "executionInfo": {
     "elapsed": 162709,
     "status": "ok",
     "timestamp": 1736056620599,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "MRGHh-Ur6YMF",
    "outputId": "383019bd-ffea-4128-d612-06b3226a3f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 Upload the Test Dataset (CSV format with 'content' and 'paper_id' columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-799cee3e-da75-402c-9163-e30ccc173d4d\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-799cee3e-da75-402c-9163-e30ccc173d4d\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test_dataset.csv to test_dataset (2).csv\n",
      "\n",
      "✅ Test Dataset Loaded. Overview:\n",
      "  paper_id                                            content\n",
      "0  paper_1  Leveraging Clustering Techniques for Enhanced\\...\n",
      "1  paper_2  Virus Propagation and their Far-Reaching\\nImpl...\n",
      "2  paper_3  Explainable Reinforcement Learning for Financi...\n",
      "3  paper_4  Graph Neural Networks Without Training: Harnes...\n",
      "4  paper_5  Collaborative Clothing Segmentation and\\nIdent...\n",
      "\n",
      "✅ Preprocessed Test Dataset saved to: /content/test_dataset_preprocessed.csv\n",
      "\n",
      "📥 Click below to download the preprocessed test dataset:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_58cee221-5cb2-4295-bc73-383f77a0da22\", \"test_dataset_preprocessed.csv\", 3700048)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6.1: Preprocess Test Dataset from CSV\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from google.colab import files\n",
    "\n",
    "# ✅ Upload Test CSV File\n",
    "print(\"📤 Upload the Test Dataset (CSV format with 'content' and 'paper_id' columns):\")\n",
    "uploaded_test = files.upload()\n",
    "test_file = list(uploaded_test.keys())[0]\n",
    "test_path = f\"/content/{test_file}\"\n",
    "\n",
    "# ✅ Load Test Dataset\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# ✅ Verify Dataset Structure\n",
    "print(\"\\n✅ Test Dataset Loaded. Overview:\")\n",
    "print(df_test.head())\n",
    "\n",
    "# Ensure required columns are present\n",
    "if 'content' not in df_test.columns or 'paper_id' not in df_test.columns:\n",
    "    raise ValueError(\"The test dataset must have 'content' and 'paper_id' columns!\")\n",
    "\n",
    "# ✅ Preprocess Text Data\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"  # Handle NaN gracefully\n",
    "\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df_test['content'] = df_test['content'].apply(preprocess_text)\n",
    "\n",
    "# ✅ Handle Missing Values\n",
    "df_test.dropna(subset=['content'], inplace=True)\n",
    "\n",
    "# ✅ Save Preprocessed Test Dataset\n",
    "preprocessed_test_csv_path = '/content/test_dataset_preprocessed.csv'\n",
    "df_test.to_csv(preprocessed_test_csv_path, index=False)\n",
    "print(f\"\\n✅ Preprocessed Test Dataset saved to: {preprocessed_test_csv_path}\")\n",
    "\n",
    "# ✅ Download Preprocessed Test Dataset\n",
    "print(\"\\n📥 Click below to download the preprocessed test dataset:\")\n",
    "files.download(preprocessed_test_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 576
    },
    "executionInfo": {
     "elapsed": 166371,
     "status": "ok",
     "timestamp": 1736056786963,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "0gCIn008657v",
    "outputId": "d252e6ef-0e76-42d8-d1d3-2832a79eb740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📤 Upload the Preprocessed Test Dataset (CSV format with 'content' and 'paper_id' columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1032d280-06a8-47bd-ba81-470f2403e333\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-1032d280-06a8-47bd-ba81-470f2403e333\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test_dataset_preprocessed.csv to test_dataset_preprocessed (2).csv\n",
      "\n",
      "✅ Test Dataset Loaded. Overview:\n",
      "  paper_id                                            content\n",
      "0  paper_1  leveraging clustering techniques for enhanced ...\n",
      "1  paper_2  virus propagation and their farreaching implic...\n",
      "2  paper_3  explainable reinforcement learning for financi...\n",
      "3  paper_4  graph neural networks without training harness...\n",
      "4  paper_5  collaborative clothing segmentation and identi...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "<ipython-input-16-54368ac29e82>:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('/content/publishability_transformer_model.pth'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚙️ Classifying Test Papers...\n",
      "\n",
      "✅ Classification Completed. Sample Results:\n",
      "  paper_id                                            content  predicted_label\n",
      "0  paper_1  leveraging clustering techniques for enhanced ...      Publishable\n",
      "1  paper_2  virus propagation and their farreaching implic...  Non-Publishable\n",
      "2  paper_3  explainable reinforcement learning for financi...      Publishable\n",
      "3  paper_4  graph neural networks without training harness...      Publishable\n",
      "4  paper_5  collaborative clothing segmentation and identi...      Publishable\n",
      "\n",
      "✅ Final classification results saved to /content/final_test_classification_results.csv\n",
      "\n",
      "📥 Click below to download the final classification results CSV:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_d0197152-6641-4caf-8145-ae84a2155fd7\", \"final_test_classification_results.csv\", 3701836)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 6.2: Classify Test Dataset with Pre-trained Transformer Model\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from google.colab import files\n",
    "\n",
    "# ✅ Load Preprocessed Test Dataset\n",
    "print(\"📤 Upload the Preprocessed Test Dataset (CSV format with 'content' and 'paper_id' columns):\")\n",
    "uploaded_test = files.upload()\n",
    "test_file = list(uploaded_test.keys())[0]\n",
    "test_path = f\"/content/{test_file}\"\n",
    "\n",
    "df_test = pd.read_csv(test_path)\n",
    "\n",
    "# ✅ Verify Dataset Structure\n",
    "print(\"\\n✅ Test Dataset Loaded. Overview:\")\n",
    "print(df_test.head())\n",
    "\n",
    "if 'content' not in df_test.columns or 'paper_id' not in df_test.columns:\n",
    "    raise ValueError(\"The test dataset must have 'content' and 'paper_id' columns!\")\n",
    "\n",
    "# ✅ Load Pre-trained Transformer Model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.load_state_dict(torch.load('/content/publishability_transformer_model.pth'))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# ✅ Function to Classify a Single Paper\n",
    "def classify_paper(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return 'Publishable' if prediction == 1 else 'Non-Publishable'\n",
    "\n",
    "# ✅ Apply Classification to Each Paper\n",
    "print(\"\\n⚙️ Classifying Test Papers...\")\n",
    "df_test['predicted_label'] = df_test['content'].apply(classify_paper)\n",
    "\n",
    "# ✅ Display Sample Results\n",
    "print(\"\\n✅ Classification Completed. Sample Results:\")\n",
    "print(df_test.head())\n",
    "\n",
    "# ✅ Save Final Results\n",
    "final_results_path = '/content/final_test_classification_results.csv'\n",
    "df_test[['paper_id', 'content', 'predicted_label']].to_csv(final_results_path, index=False)\n",
    "print(f\"\\n✅ Final classification results saved to {final_results_path}\")\n",
    "\n",
    "# ✅ Enable Download of Final Results\n",
    "print(\"\\n📥 Click below to download the final classification results CSV:\")\n",
    "files.download(final_results_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fxoDSNcG_Tcl"
   },
   "source": [
    "TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2807,
     "status": "ok",
     "timestamp": 1736056789766,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "-FwJVTec_am9",
    "outputId": "ac53de71-fa97-4e0e-e8a1-94f4de5cf360"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: pathway in /usr/local/lib/python3.10/dist-packages (0.16.3)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.11.10)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (8.1.7)\n",
      "Requirement already satisfied: geopy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.4.1)\n",
      "Requirement already satisfied: h3>=4 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.1.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.6.0)\n",
      "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.0.6)\n",
      "Requirement already satisfied: sqlglot==10.6.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (10.6.1)\n",
      "Requirement already satisfied: pyarrow>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (17.0.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.32.3)\n",
      "Requirement already satisfied: python-sat>=0.1.8.dev0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.8.dev13)\n",
      "Requirement already satisfied: beartype<0.16.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (0.15.0)\n",
      "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (13.9.4)\n",
      "Requirement already satisfied: diskcache>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (5.6.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.2.2)\n",
      "Requirement already satisfied: boto3>=1.26.76 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.35.92)\n",
      "Requirement already satisfied: google-api-python-client>=2.108.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.155.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.12.2)\n",
      "Requirement already satisfied: panel>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.5.4)\n",
      "Requirement already satisfied: jupyter-bokeh>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.0.5)\n",
      "Requirement already satisfied: jmespath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.0.1)\n",
      "Requirement already satisfied: aiohttp-cors>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (0.7.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
      "Requirement already satisfied: fs>=2.4.16 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.4.16)\n",
      "Requirement already satisfied: async-lru>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.0.4)\n",
      "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.4.2)\n",
      "Requirement already satisfied: google-cloud-pubsub>=2.21.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.27.1)\n",
      "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (from pathway) (3.25.0)\n",
      "Requirement already satisfied: pydantic~=2.9.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.9.2)\n",
      "Requirement already satisfied: gitpython>=3.1.43 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.1.43)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.18.3)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.92 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.26.76->pathway) (1.35.92)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.26.76->pathway) (0.10.4)\n",
      "Requirement already satisfied: appdirs~=1.4.3 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (1.4.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (75.1.0)\n",
      "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (1.17.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy>=2.4.0->pathway) (2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.43->pathway) (4.0.11)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.27.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.19.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.51.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.68.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (5.29.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (0.13.1)\n",
      "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.62.3)\n",
      "Requirement already satisfied: bokeh==3.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (3.6.2)\n",
      "Requirement already satisfied: ipywidgets==8.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (8.1.5)\n",
      "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (1.3.1)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (11.0.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.3.3)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (2024.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (7.34.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.66.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.29.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.22.0->pathway) (0.50b0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (6.2.0)\n",
      "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.0.3)\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.7)\n",
      "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (0.4.2)\n",
      "Requirement already satisfied: param<3.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.2.0)\n",
      "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.9.0->pathway) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.9.0->pathway) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (2024.12.14)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->pathway) (2.18.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (3.5.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.7.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->pathway) (1.17.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.43->pathway) (5.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery->pathway) (1.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=2.108.0->pathway) (3.2.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.22.0->pathway) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.3.1->pathway) (0.1.2)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.3.1->pathway) (0.5.1)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.3.1->pathway) (1.0.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.19.2)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.48)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.9.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.6.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.13)\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install pandas pathway transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 87865,
     "status": "ok",
     "timestamp": 1736057736586,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "xpJe3vX4GWTr",
    "outputId": "3e3e89fe-4655-45fa-9d60-1806a644053a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Using the Pretrained Publishability Model Loaded in Memory:\n",
      "BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n",
      "\n",
      "📤 Upload the Test Dataset (CSV format with 'paper_id' and 'content' columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-03ff4250-ced7-4bd8-a4ce-959a8d0f5407\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-03ff4250-ced7-4bd8-a4ce-959a8d0f5407\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test_dataset.csv to test_dataset (4).csv\n",
      "\n",
      "✅ Test Dataset Loaded. Overview:\n",
      "  paper_id                                            content\n",
      "0  paper_1  Leveraging Clustering Techniques for Enhanced\\...\n",
      "1  paper_2  Virus Propagation and their Far-Reaching\\nImpl...\n",
      "2  paper_3  Explainable Reinforcement Learning for Financi...\n",
      "3  paper_4  Graph Neural Networks Without Training: Harnes...\n",
      "4  paper_5  Collaborative Clothing Segmentation and\\nIdent...\n",
      "\n",
      "⚙️ Classifying Papers for Publishability...\n",
      "\n",
      "✅ Sample Classification Results:\n",
      "  paper_id                                            content publishable\n",
      "0  paper_1  leveraging clustering techniques for enhanced ...         Yes\n",
      "1  paper_2  virus propagation and their farreaching implic...          No\n",
      "2  paper_3  explainable reinforcement learning for financi...         Yes\n",
      "3  paper_4  graph neural networks without training harness...         Yes\n",
      "4  paper_5  collaborative clothing segmentation and identi...         Yes\n",
      "\n",
      "✅ Publishability results saved to /content/publishability_results.csv\n",
      "\n",
      "📥 Click below to download the publishability results CSV:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_ca088d13-f30d-4c5d-bae7-e1342388a3ec\", \"publishability_results.csv\", 3700562)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Classify Test Dataset Using Loaded Pretrained Publishability Model\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# ✅ Verify the Model is Loaded\n",
    "print(\"\\n✅ Using the Pretrained Publishability Model Loaded in Memory:\")\n",
    "print(model)\n",
    "\n",
    "# ✅ Upload the Test Dataset\n",
    "from google.colab import files\n",
    "\n",
    "print(\"\\n📤 Upload the Test Dataset (CSV format with 'paper_id' and 'content' columns):\")\n",
    "uploaded_test = files.upload()\n",
    "test_file = list(uploaded_test.keys())[0]\n",
    "test_path = f\"/content/{test_file}\"\n",
    "\n",
    "# ✅ Load the Test Dataset\n",
    "df_test = pd.read_csv(test_path)\n",
    "print(\"\\n✅ Test Dataset Loaded. Overview:\")\n",
    "print(df_test.head())\n",
    "\n",
    "# Verify necessary columns\n",
    "if 'content' not in df_test.columns or 'paper_id' not in df_test.columns:\n",
    "    raise ValueError(\"The test dataset must have 'content' and 'paper_id' columns!\")\n",
    "\n",
    "# ✅ Preprocess Text Data\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df_test['content'] = df_test['content'].apply(preprocess_text)\n",
    "\n",
    "# ✅ Tokenizer (Using the Same Tokenizer as Training)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# ✅ Classify Papers for Publishability\n",
    "def classify_publishability(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n",
    "    inputs = {key: val.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu')) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return 'Yes' if prediction == 1 else 'No'\n",
    "\n",
    "print(\"\\n⚙️ Classifying Papers for Publishability...\")\n",
    "df_test['publishable'] = df_test['content'].apply(classify_publishability)\n",
    "\n",
    "# ✅ Display Sample Results\n",
    "print(\"\\n✅ Sample Classification Results:\")\n",
    "print(df_test.head())\n",
    "\n",
    "# ✅ Save Publishability Results\n",
    "publishability_results_path = '/content/publishability_results.csv'\n",
    "df_test.to_csv(publishability_results_path, index=False)\n",
    "print(f\"\\n✅ Publishability results saved to {publishability_results_path}\")\n",
    "\n",
    "# ✅ Download Publishability Results\n",
    "from google.colab import files\n",
    "\n",
    "print(\"\\n📥 Click below to download the publishability results CSV:\")\n",
    "files.download(publishability_results_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 691
    },
    "executionInfo": {
     "elapsed": 107840,
     "status": "ok",
     "timestamp": 1736058633879,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "xzkmXL4pJsh4",
    "outputId": "dc692230-e919-4d0a-b6eb-83a8ab99d8bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📤 Upload PDFs for TMLR:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-6cd301b1-f40d-40cd-a77b-8fde746b3d2b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-6cd301b1-f40d-40cd-a77b-8fde746b3d2b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving R014.pdf to R014 (4).pdf\n",
      "Saving R015.pdf to R015 (4).pdf\n",
      "\n",
      "📤 Upload PDFs for NeurIPS:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-bfb6fd1b-3eee-485b-8351-29a7ba13a088\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-bfb6fd1b-3eee-485b-8351-29a7ba13a088\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving R012.pdf to R012 (4).pdf\n",
      "Saving R013.pdf to R013 (4).pdf\n",
      "\n",
      "📤 Upload PDFs for KDD:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-36cc99a1-4acc-42af-b956-1baf6d44ac14\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-36cc99a1-4acc-42af-b956-1baf6d44ac14\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving R010.pdf to R010 (4).pdf\n",
      "Saving R011.pdf to R011 (4).pdf\n",
      "\n",
      "📤 Upload PDFs for EMNLP:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7648dd32-6293-402c-b74d-d99c16fa8200\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-7648dd32-6293-402c-b74d-d99c16fa8200\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving R008.pdf to R008 (4).pdf\n",
      "Saving R009.pdf to R009 (4).pdf\n",
      "\n",
      "📤 Upload PDFs for CVPR:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-0ca790d9-a3d8-45fd-ac33-6cb84085838b\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-0ca790d9-a3d8-45fd-ac33-6cb84085838b\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving R006.pdf to R006 (4).pdf\n",
      "Saving R007.pdf to R007 (4).pdf\n",
      "\n",
      "✅ Conference datasets combined and saved to /content/conference_combined_dataset.csv\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_17f758b0-4c07-4b8c-8ee8-e9311e0506a7\", \"conference_combined_dataset.csv\", 285386)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Process Conference-Specific PDF Datasets into CSV\n",
    "\n",
    "import pandas as pd\n",
    "import fitz  # PyMuPDF for PDF text extraction\n",
    "from google.colab import files\n",
    "\n",
    "# ✅ Upload Conference PDFs\n",
    "conference_data = {}\n",
    "conferences = ['TMLR', 'NeurIPS', 'KDD', 'EMNLP', 'CVPR']\n",
    "\n",
    "for conference in conferences:\n",
    "    print(f\"\\n📤 Upload PDFs for {conference}:\")\n",
    "    uploaded_pdfs = files.upload()\n",
    "    pdf_files = list(uploaded_pdfs.keys())\n",
    "\n",
    "    extracted_data = []\n",
    "    for i, pdf_file in enumerate(pdf_files):\n",
    "        doc = fitz.open(pdf_file)\n",
    "        text = \"\"\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "        extracted_data.append({\"paper_id\": f\"{conference}_paper_{i+1}\", \"content\": text, \"conference\": conference})\n",
    "\n",
    "    # Store in a DataFrame\n",
    "    conference_data[conference] = pd.DataFrame(extracted_data)\n",
    "\n",
    "# ✅ Combine All Conference Data\n",
    "df_conference_combined = pd.concat(conference_data.values(), ignore_index=True)\n",
    "\n",
    "# ✅ Save as CSV\n",
    "conference_csv_path = '/content/conference_combined_dataset.csv'\n",
    "df_conference_combined.to_csv(conference_csv_path, index=False)\n",
    "print(f\"\\n✅ Conference datasets combined and saved to {conference_csv_path}\")\n",
    "\n",
    "# ✅ Download Combined Dataset\n",
    "files.download(conference_csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 624
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1736058667677,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "VHM9RUrMKJg1",
    "outputId": "5e03636b-c639-4a6d-ed3a-f61114f598fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Conference Dataset Loaded. Overview:\n",
      "          paper_id                                            content  \\\n",
      "0     TMLR_paper_1  Addressing Min-Max Challenges in Nonconvex-Non...   \n",
      "1     TMLR_paper_2  Examining the Convergence of Denoising Diffusi...   \n",
      "2  NeurIPS_paper_1  Safe Predictors for Input-Output Specification...   \n",
      "3  NeurIPS_paper_2  Generalization in ReLU Networks via Restricted...   \n",
      "4      KDD_paper_1  Detecting Medication Usage in Parkinson’s Dise...   \n",
      "\n",
      "  conference  \n",
      "0       TMLR  \n",
      "1       TMLR  \n",
      "2    NeurIPS  \n",
      "3    NeurIPS  \n",
      "4        KDD  \n",
      "\n",
      "⚙️ Preprocessing Text Data...\n",
      "\n",
      "✅ Sample Preprocessed Text Data:\n",
      "          paper_id                                            content  \\\n",
      "0     TMLR_paper_1  addressing minmax challenges in nonconvexnonco...   \n",
      "1     TMLR_paper_2  examining the convergence of denoising diffusi...   \n",
      "2  NeurIPS_paper_1  safe predictors for inputoutput specification ...   \n",
      "3  NeurIPS_paper_2  generalization in relu networks via restricted...   \n",
      "4      KDD_paper_1  detecting medication usage in parkinsons disea...   \n",
      "\n",
      "  conference  \n",
      "0       TMLR  \n",
      "1       TMLR  \n",
      "2    NeurIPS  \n",
      "3    NeurIPS  \n",
      "4        KDD  \n",
      "\n",
      "✅ Preprocessed Conference Dataset saved to: /content/preprocessed_conference_dataset.csv\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_18036ebe-0972-4c2e-a390-fc9ca67fc9c5\", \"preprocessed_conference_dataset.csv\", 254843)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 2: Preprocess Conference Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from google.colab import files\n",
    "\n",
    "# ✅ Load the Conference Dataset\n",
    "conference_csv_path = '/content/conference_combined_dataset.csv'\n",
    "df_conference = pd.read_csv(conference_csv_path)\n",
    "\n",
    "print(\"\\n✅ Conference Dataset Loaded. Overview:\")\n",
    "print(df_conference.head())\n",
    "\n",
    "# ✅ Verify Required Columns\n",
    "if 'content' not in df_conference.columns or 'conference' not in df_conference.columns:\n",
    "    raise ValueError(\"The dataset must contain 'content' and 'conference' columns!\")\n",
    "\n",
    "# ✅ Preprocess Text Data\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()  # Lowercase conversion\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove special characters and numbers\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "# Apply Preprocessing\n",
    "print(\"\\n⚙️ Preprocessing Text Data...\")\n",
    "df_conference['content'] = df_conference['content'].apply(preprocess_text)\n",
    "\n",
    "# ✅ Handle Missing Values\n",
    "# Drop rows with empty 'content' after preprocessing\n",
    "df_conference.dropna(subset=['content'], inplace=True)\n",
    "df_conference = df_conference[df_conference['content'].str.strip() != '']\n",
    "\n",
    "# ✅ Verify Preprocessed Data\n",
    "print(\"\\n✅ Sample Preprocessed Text Data:\")\n",
    "print(df_conference.head())\n",
    "\n",
    "# ✅ Save Preprocessed Dataset\n",
    "preprocessed_conference_path = '/content/preprocessed_conference_dataset.csv'\n",
    "df_conference.to_csv(preprocessed_conference_path, index=False)\n",
    "print(f\"\\n✅ Preprocessed Conference Dataset saved to: {preprocessed_conference_path}\")\n",
    "\n",
    "# ✅ Enable Download\n",
    "files.download(preprocessed_conference_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 14243,
     "status": "ok",
     "timestamp": 1736060476856,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "u4fCYEU8Q-S8",
    "outputId": "48182d10-c5a4-4dd5-861a-f8b4911b510a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Preprocessed Conference Dataset Loaded. Overview:\n",
      "          paper_id                                            content  \\\n",
      "0     TMLR_paper_1  addressing minmax challenges in nonconvexnonco...   \n",
      "1     TMLR_paper_2  examining the convergence of denoising diffusi...   \n",
      "2  NeurIPS_paper_1  safe predictors for inputoutput specification ...   \n",
      "3  NeurIPS_paper_2  generalization in relu networks via restricted...   \n",
      "4      KDD_paper_1  detecting medication usage in parkinsons disea...   \n",
      "\n",
      "  conference  \n",
      "0       TMLR  \n",
      "1       TMLR  \n",
      "2    NeurIPS  \n",
      "3    NeurIPS  \n",
      "4        KDD  \n",
      "\n",
      "✅ Label Mapping:\n",
      "{'CVPR': 0, 'EMNLP': 1, 'KDD': 2, 'NeurIPS': 3, 'TMLR': 4}\n",
      "\n",
      "✅ Adjusted Class Weights: tensor([1., 1., 1., 1., 1.], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s, loss=1.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Average Loss for Epoch 1: 1.6973\n",
      "\n",
      "🔄 Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Average Loss for Epoch 2: 1.5300\n",
      "\n",
      "🔄 Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=1.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Average Loss for Epoch 3: 1.4872\n",
      "\n",
      "🔄 Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  1.09it/s, loss=1.41]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Average Loss for Epoch 4: 1.4130\n",
      "\n",
      "🔄 Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=1.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Average Loss for Epoch 5: 1.3976\n",
      "\n",
      "🔄 Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=1.39]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Average Loss for Epoch 6: 1.3938\n",
      "\n",
      "🔄 Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=1.37]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Average Loss for Epoch 7: 1.3735\n",
      "\n",
      "🔄 Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  1.08it/s, loss=1.31]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Average Loss for Epoch 8: 1.3133\n",
      "\n",
      "🔄 Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Average Loss for Epoch 9: 1.2141\n",
      "\n",
      "🔄 Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  1.07it/s, loss=1.26]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Average Loss for Epoch 10: 1.2632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Evaluation Metrics:\n",
      "✅ Accuracy: 0.7000\n",
      "✅ F1-Score: 0.6267\n",
      "✅ Precision: 0.6333\n",
      "✅ Recall: 0.7000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Model saved to /content/conference_classification_model.pth\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_c3d7ad89-5d94-4bea-a1fd-7465ccaa7ee1\", \"conference_classification_model.pth\", 438030936)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 3: Full Fine-Tune Transformer Model for Conference Classification\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ 1. Load Preprocessed Dataset\n",
    "preprocessed_conference_path = '/content/preprocessed_conference_dataset.csv'\n",
    "df_conference = pd.read_csv(preprocessed_conference_path)\n",
    "\n",
    "print(\"\\n✅ Preprocessed Conference Dataset Loaded. Overview:\")\n",
    "print(df_conference.head())\n",
    "\n",
    "# ✅ 2. Encode Conference Labels\n",
    "label_encoder = LabelEncoder()\n",
    "df_conference['conference_label'] = label_encoder.fit_transform(df_conference['conference'])\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"\\n✅ Label Mapping:\")\n",
    "print(label_mapping)\n",
    "\n",
    "# ✅ 3. Handle Class Imbalance with Class Weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(df_conference['conference_label']),\n",
    "    y=df_conference['conference_label']\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"\\n✅ Adjusted Class Weights:\", class_weights)\n",
    "\n",
    "# ✅ 4. Prepare Dataset\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "class ConferenceDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenizer(\n",
    "            texts.tolist(), truncation=True, padding=True, max_length=512, return_tensors='pt'\n",
    "        )\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "dataset = ConferenceDataset(df_conference['content'], df_conference['conference_label'])\n",
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# ✅ 5. Load Transformer Model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(label_mapping))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# ✅ 6. Optimizer, Scheduler, and Loss Function\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "loss_function = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "num_training_steps = len(data_loader) * 10  # 10 epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "# ✅ 7. Early Stopping Mechanism\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=3):\n",
    "        self.patience = patience\n",
    "        self.best_loss = float('inf')\n",
    "        self.counter = 0\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if val_loss < self.best_loss:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"\\n🛑 Early stopping triggered!\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3)\n",
    "\n",
    "# ✅ 8. Training Function\n",
    "def train_model(model, data_loader, optimizer, scheduler, loss_function, device, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f'\\n🔄 Epoch {epoch + 1}/{epochs}')\n",
    "        total_loss = 0\n",
    "        loop = tqdm(data_loader, leave=True)\n",
    "        for batch in loop:\n",
    "            optimizer.zero_grad()\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = loss_function(outputs.logits, batch['labels'])\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loop.set_description(f'Epoch {epoch + 1}')\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = total_loss / len(data_loader)\n",
    "        print(f\"\\n✅ Average Loss for Epoch {epoch + 1}: {avg_loss:.4f}\")\n",
    "\n",
    "        if early_stopping(avg_loss):\n",
    "            break\n",
    "\n",
    "# ✅ 9. Evaluation Function\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            batch = {key: val.to(device) for key, val in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            labels = batch['labels'].cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels)\n",
    "\n",
    "    acc = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "\n",
    "    print(\"\\n📊 Evaluation Metrics:\")\n",
    "    print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "    print(f\"✅ F1-Score: {f1:.4f}\")\n",
    "    print(f\"✅ Precision: {precision:.4f}\")\n",
    "    print(f\"✅ Recall: {recall:.4f}\")\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "# ✅ 10. Train and Evaluate Model\n",
    "train_model(model, data_loader, optimizer, scheduler, loss_function, device)\n",
    "evaluate_model(model, data_loader, device)\n",
    "\n",
    "# ✅ 11. Save Model\n",
    "model_save_path = '/content/conference_classification_model.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"\\n✅ Model saved to {model_save_path}\")\n",
    "\n",
    "# ✅ 12. Download Model\n",
    "from google.colab import files\n",
    "files.download(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1736060906796,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "DUGqM40qSyBn",
    "outputId": "29f83f91-f355-4786-a8c3-70ed3b701f74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Listing all files in /content:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.config',\n",
       " 'P001.pdf',\n",
       " 'P055 (1).pdf',\n",
       " 'P097 (2).pdf',\n",
       " 'P039 (1).pdf',\n",
       " 'P086.pdf',\n",
       " 'P046.pdf',\n",
       " 'P109.pdf',\n",
       " 'P017.pdf',\n",
       " 'P042 (1).pdf',\n",
       " 'P015 (1).pdf',\n",
       " 'P057 (2).pdf',\n",
       " 'P027 (2).pdf',\n",
       " 'P115 (2).pdf',\n",
       " 'P001 (2).pdf',\n",
       " 'R009 (2).pdf',\n",
       " 'test_dataset_preprocessed.csv',\n",
       " 'P078 (2).pdf',\n",
       " 'P092.pdf',\n",
       " 'P074 (2).pdf',\n",
       " 'P101 (2).pdf',\n",
       " 'R013 (4).pdf',\n",
       " 'P104.pdf',\n",
       " 'P024 (1).pdf',\n",
       " 'R005.pdf',\n",
       " 'P065.pdf',\n",
       " 'P100 (1).pdf',\n",
       " 'P134 (2).pdf',\n",
       " 'P098 (1).pdf',\n",
       " 'P002.pdf',\n",
       " 'P033.pdf',\n",
       " 'P121 (2).pdf',\n",
       " 'P119 (2).pdf',\n",
       " 'R006.pdf',\n",
       " 'P114 (2).pdf',\n",
       " 'P043.pdf',\n",
       " 'P061.pdf',\n",
       " 'P071 (1).pdf',\n",
       " 'P041.pdf',\n",
       " 'P040.pdf',\n",
       " 'P117 (2).pdf',\n",
       " 'P021 (1).pdf',\n",
       " 'P005 (1).pdf',\n",
       " 'P110 (1).pdf',\n",
       " 'final_test_classification_results.csv',\n",
       " 'R007 (4).pdf',\n",
       " 'P127 (1).pdf',\n",
       " 'R002.pdf',\n",
       " 'P028 (1).pdf',\n",
       " 'P014 (2).pdf',\n",
       " 'P062.pdf',\n",
       " 'P035.pdf',\n",
       " 'P066.pdf',\n",
       " 'P056 (2).pdf',\n",
       " 'P026 (2).pdf',\n",
       " 'P093.pdf',\n",
       " 'P055 (2).pdf',\n",
       " 'test_dataset (4).csv',\n",
       " 'R014 (2).pdf',\n",
       " 'P018.pdf',\n",
       " 'P088.pdf',\n",
       " 'P060 (2).pdf',\n",
       " 'P104 (1).pdf',\n",
       " 'test_dataset_preprocessed (2).csv',\n",
       " 'P022 (1).pdf',\n",
       " 'P123.pdf',\n",
       " 'P090 (2).pdf',\n",
       " 'P017 (1).pdf',\n",
       " 'P124.pdf',\n",
       " 'P016 (1).pdf',\n",
       " 'conference_combined_dataset.csv',\n",
       " 'P067 (2).pdf',\n",
       " 'R001.pdf',\n",
       " 'P044 (2).pdf',\n",
       " 'P004 (2).pdf',\n",
       " 'P133 (2).pdf',\n",
       " 'P007.pdf',\n",
       " 'P033 (2).pdf',\n",
       " 'P092 (1).pdf',\n",
       " 'R006 (3).pdf',\n",
       " 'test_dataset.csv',\n",
       " 'P054.pdf',\n",
       " 'P035 (2).pdf',\n",
       " 'P050 (1).pdf',\n",
       " 'P035 (1).pdf',\n",
       " 'P056.pdf',\n",
       " 'P106 (1).pdf',\n",
       " 'P066 (2).pdf',\n",
       " 'merged_training_dataset.csv',\n",
       " 'P067.pdf',\n",
       " 'P052.pdf',\n",
       " 'P077 (2).pdf',\n",
       " 'P117.pdf',\n",
       " 'P067 (1).pdf',\n",
       " 'P022 (2).pdf',\n",
       " 'P023 (1).pdf',\n",
       " 'P082 (1).pdf',\n",
       " 'P006 (2).pdf',\n",
       " 'P072.pdf',\n",
       " 'P012.pdf',\n",
       " 'P098.pdf',\n",
       " 'publishability_transformer_model.pth',\n",
       " 'P107.pdf',\n",
       " 'P124 (2).pdf',\n",
       " 'P091 (2).pdf',\n",
       " 'P108 (2).pdf',\n",
       " 'R012.pdf',\n",
       " 'P108 (1).pdf',\n",
       " 'P068.pdf',\n",
       " 'P044 (1).pdf',\n",
       " 'P096.pdf',\n",
       " 'P089 (1).pdf',\n",
       " 'P046 (2).pdf',\n",
       " 'P063.pdf',\n",
       " 'R004 (2).pdf',\n",
       " 'P031.pdf',\n",
       " 'P125.pdf',\n",
       " 'P030.pdf',\n",
       " 'P049 (2).pdf',\n",
       " 'P048 (2).pdf',\n",
       " 'P032.pdf',\n",
       " 'P041 (2).pdf',\n",
       " 'R004.pdf',\n",
       " 'R014.pdf',\n",
       " 'P046 (1).pdf',\n",
       " 'R010 (2).pdf',\n",
       " 'P037.pdf',\n",
       " 'P069 (2).pdf',\n",
       " 'P093 (2).pdf',\n",
       " 'P103 (1).pdf',\n",
       " 'P116 (1).pdf',\n",
       " 'P021 (2).pdf',\n",
       " 'P096 (2).pdf',\n",
       " 'P114.pdf',\n",
       " 'R012 (3).pdf',\n",
       " 'P109 (1).pdf',\n",
       " 'P102 (1).pdf',\n",
       " 'R011 (4).pdf',\n",
       " 'P107 (2).pdf',\n",
       " 'conference_classification_model_adjusted.pth',\n",
       " 'P077.pdf',\n",
       " 'R015 (1).pdf',\n",
       " 'P126.pdf',\n",
       " 'P010 (1).pdf',\n",
       " 'P029 (2).pdf',\n",
       " 'P015 (2).pdf',\n",
       " 'P091.pdf',\n",
       " 'P070 (2).pdf',\n",
       " 'P058.pdf',\n",
       " 'P094 (1).pdf',\n",
       " 'R010 (3).pdf',\n",
       " 'P045.pdf',\n",
       " 'P061 (1).pdf',\n",
       " 'P093 (1).pdf',\n",
       " 'P082 (2).pdf',\n",
       " 'P112 (2).pdf',\n",
       " 'R015.pdf',\n",
       " 'P082.pdf',\n",
       " 'test_dataset (3).csv',\n",
       " 'P033 (1).pdf',\n",
       " 'P047 (1).pdf',\n",
       " 'R013 (3).pdf',\n",
       " 'P030 (2).pdf',\n",
       " 'P040 (2).pdf',\n",
       " 'P037 (1).pdf',\n",
       " 'R015 (2).pdf',\n",
       " 'P064 (1).pdf',\n",
       " 'P064 (2).pdf',\n",
       " 'P116.pdf',\n",
       " 'P101.pdf',\n",
       " 'R013 (1).pdf',\n",
       " 'R011 (3).pdf',\n",
       " 'P070 (1).pdf',\n",
       " 'P122 (1).pdf',\n",
       " 'P029 (1).pdf',\n",
       " 'P095.pdf',\n",
       " 'P124 (1).pdf',\n",
       " 'P061 (2).pdf',\n",
       " 'P006 (1).pdf',\n",
       " 'P025.pdf',\n",
       " 'P075 (2).pdf',\n",
       " 'P099 (2).pdf',\n",
       " 'P045 (1).pdf',\n",
       " 'P091 (1).pdf',\n",
       " 'P041 (1).pdf',\n",
       " 'R002 (2).pdf',\n",
       " 'P079 (1).pdf',\n",
       " 'P103 (2).pdf',\n",
       " 'P027 (1).pdf',\n",
       " 'R006 (1).pdf',\n",
       " 'P125 (1).pdf',\n",
       " 'P110 (2).pdf',\n",
       " 'P001 (1).pdf',\n",
       " 'P133 (1).pdf',\n",
       " 'P128.pdf',\n",
       " 'P075 (1).pdf',\n",
       " 'P024.pdf',\n",
       " 'P030 (1).pdf',\n",
       " 'R004 (1).pdf',\n",
       " 'P014.pdf',\n",
       " 'P121 (1).pdf',\n",
       " 'P062 (1).pdf',\n",
       " 'R015 (3).pdf',\n",
       " 'P071.pdf',\n",
       " 'P012 (2).pdf',\n",
       " 'P087.pdf',\n",
       " 'P090 (1).pdf',\n",
       " 'P043 (1).pdf',\n",
       " 'R007 (3).pdf',\n",
       " 'P043 (2).pdf',\n",
       " 'P055.pdf',\n",
       " 'P008 (2).pdf',\n",
       " 'P130.pdf',\n",
       " 'P085.pdf',\n",
       " 'P009 (2).pdf',\n",
       " 'P114 (1).pdf',\n",
       " 'P063 (1).pdf',\n",
       " 'P073 (1).pdf',\n",
       " 'P087 (2).pdf',\n",
       " 'P053 (1).pdf',\n",
       " 'P005 (2).pdf',\n",
       " 'P028 (2).pdf',\n",
       " 'P106.pdf',\n",
       " 'P058 (1).pdf',\n",
       " 'P074 (1).pdf',\n",
       " 'P056 (1).pdf',\n",
       " 'P102.pdf',\n",
       " 'P026 (1).pdf',\n",
       " 'R011.pdf',\n",
       " 'P079 (2).pdf',\n",
       " 'P108.pdf',\n",
       " 'P025 (1).pdf',\n",
       " 'P060 (1).pdf',\n",
       " 'P131 (2).pdf',\n",
       " 'P078.pdf',\n",
       " 'P038.pdf',\n",
       " 'P068 (1).pdf',\n",
       " 'P071 (2).pdf',\n",
       " 'P134 (1).pdf',\n",
       " 'R014 (3).pdf',\n",
       " 'P083 (2).pdf',\n",
       " 'P097 (1).pdf',\n",
       " 'P023.pdf',\n",
       " 'P096 (1).pdf',\n",
       " 'P089 (2).pdf',\n",
       " 'P021.pdf',\n",
       " 'P059 (1).pdf',\n",
       " 'R006 (2).pdf',\n",
       " 'P038 (2).pdf',\n",
       " 'P100.pdf',\n",
       " 'P115.pdf',\n",
       " 'P105 (2).pdf',\n",
       " 'P069.pdf',\n",
       " 'R003.pdf',\n",
       " 'P099.pdf',\n",
       " 'publishability_results.csv',\n",
       " 'P084 (1).pdf',\n",
       " 'R005 (2).pdf',\n",
       " 'R006 (4).pdf',\n",
       " 'P122 (2).pdf',\n",
       " 'P053.pdf',\n",
       " 'P002 (1).pdf',\n",
       " 'R011 (1).pdf',\n",
       " 'P069 (1).pdf',\n",
       " 'R009 (3).pdf',\n",
       " 'P058 (2).pdf',\n",
       " 'P008.pdf',\n",
       " 'P075.pdf',\n",
       " 'test_dataset_preprocessed (3).csv',\n",
       " 'P080.pdf',\n",
       " 'P052 (2).pdf',\n",
       " 'P105.pdf',\n",
       " 'R012 (2).pdf',\n",
       " 'P119.pdf',\n",
       " 'R007 (1).pdf',\n",
       " 'P115 (1).pdf',\n",
       " 'P020 (1).pdf',\n",
       " 'test_dataset (2).csv',\n",
       " 'P037 (2).pdf',\n",
       " 'P011.pdf',\n",
       " 'P083.pdf',\n",
       " 'P047.pdf',\n",
       " 'P083 (1).pdf',\n",
       " 'P112 (1).pdf',\n",
       " 'P072 (1).pdf',\n",
       " 'preprocessed_conference_dataset.csv',\n",
       " 'P076.pdf',\n",
       " 'R014 (1).pdf',\n",
       " 'P076 (2).pdf',\n",
       " 'R009 (1).pdf',\n",
       " 'P051.pdf',\n",
       " 'R012 (1).pdf',\n",
       " 'R005 (1).pdf',\n",
       " 'R008 (2).pdf',\n",
       " 'P007 (1).pdf',\n",
       " 'P090.pdf',\n",
       " 'P011 (2).pdf',\n",
       " 'P094.pdf',\n",
       " 'P080 (1).pdf',\n",
       " 'P085 (1).pdf',\n",
       " 'P010.pdf',\n",
       " 'P129 (1).pdf',\n",
       " 'R014 (4).pdf',\n",
       " 'P027.pdf',\n",
       " 'P084.pdf',\n",
       " 'P126 (2).pdf',\n",
       " 'P134.pdf',\n",
       " 'P078 (1).pdf',\n",
       " 'P009.pdf',\n",
       " 'R011 (2).pdf',\n",
       " 'P077 (1).pdf',\n",
       " 'P086 (1).pdf',\n",
       " 'P007 (2).pdf',\n",
       " 'P081.pdf',\n",
       " 'P098 (2).pdf',\n",
       " 'P122.pdf',\n",
       " 'validation_results.csv',\n",
       " 'R007 (2).pdf',\n",
       " 'P048 (1).pdf',\n",
       " 'P059 (2).pdf',\n",
       " 'P004.pdf',\n",
       " 'R012 (4).pdf',\n",
       " 'P010 (2).pdf',\n",
       " 'P107 (1).pdf',\n",
       " 'P128 (1).pdf',\n",
       " 'P024 (2).pdf',\n",
       " 'preprocessed_training_dataset.csv',\n",
       " 'R008 (4).pdf',\n",
       " 'R008 (3).pdf',\n",
       " 'R001 (1).pdf',\n",
       " 'P135 (1).pdf',\n",
       " 'P119 (1).pdf',\n",
       " 'P104 (2).pdf',\n",
       " 'P062 (2).pdf',\n",
       " 'P081 (1).pdf',\n",
       " 'P028.pdf',\n",
       " 'P053 (2).pdf',\n",
       " 'P120 (1).pdf',\n",
       " 'R013.pdf',\n",
       " 'P032 (1).pdf',\n",
       " 'P118 (1).pdf',\n",
       " 'P127.pdf',\n",
       " 'P131 (1).pdf',\n",
       " 'P034 (2).pdf',\n",
       " 'P101 (1).pdf',\n",
       " 'R015 (4).pdf',\n",
       " 'P079.pdf',\n",
       " 'P092 (2).pdf',\n",
       " 'P074.pdf',\n",
       " 'P135 (2).pdf',\n",
       " 'P111 (2).pdf',\n",
       " 'R002 (1).pdf',\n",
       " 'P123 (1).pdf',\n",
       " 'P009 (1).pdf',\n",
       " 'P121.pdf',\n",
       " 'P130 (1).pdf',\n",
       " 'P085 (2).pdf',\n",
       " 'P052 (1).pdf',\n",
       " 'P044.pdf',\n",
       " 'P031 (1).pdf',\n",
       " 'P003.pdf',\n",
       " 'P118 (2).pdf',\n",
       " 'P072 (2).pdf',\n",
       " 'P113.pdf',\n",
       " 'P013 (2).pdf',\n",
       " 'P039 (2).pdf',\n",
       " 'P003 (1).pdf',\n",
       " 'P116 (2).pdf',\n",
       " 'R013 (2).pdf',\n",
       " 'P073 (2).pdf',\n",
       " 'test_dataset (1).csv',\n",
       " 'P059.pdf',\n",
       " 'P026.pdf',\n",
       " 'R010 (1).pdf',\n",
       " 'P005.pdf',\n",
       " 'R003 (1).pdf',\n",
       " 'P034.pdf',\n",
       " 'P018 (1).pdf',\n",
       " 'P003 (2).pdf',\n",
       " 'P084 (2).pdf',\n",
       " 'P049 (1).pdf',\n",
       " 'P016 (2).pdf',\n",
       " 'P086 (2).pdf',\n",
       " 'P117 (1).pdf',\n",
       " 'P070.pdf',\n",
       " 'P103.pdf',\n",
       " 'P023 (2).pdf',\n",
       " 'P068 (2).pdf',\n",
       " 'P099 (1).pdf',\n",
       " 'P045 (2).pdf',\n",
       " 'P105 (1).pdf',\n",
       " 'conference_classification_model.pth',\n",
       " 'P120.pdf',\n",
       " 'P060.pdf',\n",
       " 'P087 (1).pdf',\n",
       " 'P063 (2).pdf',\n",
       " 'R001 (2).pdf',\n",
       " 'P051 (1).pdf',\n",
       " 'P042.pdf',\n",
       " 'P015.pdf',\n",
       " 'P002 (2).pdf',\n",
       " 'P113 (2).pdf',\n",
       " 'P020 (2).pdf',\n",
       " 'P095 (1).pdf',\n",
       " 'P076 (1).pdf',\n",
       " 'P128 (2).pdf',\n",
       " 'P132.pdf',\n",
       " 'R009 (4).pdf',\n",
       " 'P040 (1).pdf',\n",
       " 'P066 (1).pdf',\n",
       " 'P112.pdf',\n",
       " 'P113 (1).pdf',\n",
       " 'P110.pdf',\n",
       " 'P095 (2).pdf',\n",
       " 'P057.pdf',\n",
       " 'P089.pdf',\n",
       " 'P073.pdf',\n",
       " 'R007.pdf',\n",
       " 'P054 (2).pdf',\n",
       " 'P109 (2).pdf',\n",
       " 'P004 (1).pdf',\n",
       " 'P065 (2).pdf',\n",
       " 'P106 (2).pdf',\n",
       " 'P019 (1).pdf',\n",
       " 'P049.pdf',\n",
       " 'P036 (1).pdf',\n",
       " 'P018 (2).pdf',\n",
       " 'P118.pdf',\n",
       " 'P097.pdf',\n",
       " 'P036 (2).pdf',\n",
       " 'P111.pdf',\n",
       " 'P029.pdf',\n",
       " 'test_dataset_preprocessed (1).csv',\n",
       " 'P081 (2).pdf',\n",
       " 'P125 (2).pdf',\n",
       " 'P080 (2).pdf',\n",
       " 'P013 (1).pdf',\n",
       " 'R008.pdf',\n",
       " 'P012 (1).pdf',\n",
       " 'P054 (1).pdf',\n",
       " 'P133.pdf',\n",
       " 'P016.pdf',\n",
       " 'P038 (1).pdf',\n",
       " 'P047 (2).pdf',\n",
       " 'P048.pdf',\n",
       " 'P102 (2).pdf',\n",
       " 'R008 (1).pdf',\n",
       " 'P019.pdf',\n",
       " 'P064.pdf',\n",
       " 'P025 (2).pdf',\n",
       " 'P042 (2).pdf',\n",
       " 'R009.pdf',\n",
       " 'P129 (2).pdf',\n",
       " 'P014 (1).pdf',\n",
       " 'P100 (2).pdf',\n",
       " 'P129.pdf',\n",
       " 'P135.pdf',\n",
       " 'R010.pdf',\n",
       " 'P088 (1).pdf',\n",
       " 'R003 (2).pdf',\n",
       " 'P006.pdf',\n",
       " 'P120 (2).pdf',\n",
       " 'P132 (2).pdf',\n",
       " 'P088 (2).pdf',\n",
       " 'P111 (1).pdf',\n",
       " 'P050.pdf',\n",
       " 'P065 (1).pdf',\n",
       " 'P008 (1).pdf',\n",
       " 'P127 (2).pdf',\n",
       " 'P057 (1).pdf',\n",
       " 'P130 (2).pdf',\n",
       " 'P051 (2).pdf',\n",
       " 'P013.pdf',\n",
       " 'P011 (1).pdf',\n",
       " 'P131.pdf',\n",
       " 'P019 (2).pdf',\n",
       " 'P123 (2).pdf',\n",
       " 'P039.pdf',\n",
       " 'P050 (2).pdf',\n",
       " 'P094 (2).pdf',\n",
       " 'P022.pdf',\n",
       " 'P034 (1).pdf',\n",
       " 'P126 (1).pdf',\n",
       " 'P132 (1).pdf',\n",
       " 'P031 (2).pdf',\n",
       " 'P020.pdf',\n",
       " 'P036.pdf',\n",
       " 'P017 (2).pdf',\n",
       " 'P032 (2).pdf',\n",
       " 'R010 (4).pdf',\n",
       " 'sample_data']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check for the model file in the content directory\n",
    "print(\"📂 Listing all files in /content:\")\n",
    "os.listdir('/content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03LU4Y2ZS4T9"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '/content/publishability_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1736060951228,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "DXFIbWwGS7FA",
    "outputId": "73117c31-3395-49be-f44a-2f9bec555199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Using the Publishability Model already in memory.\n"
     ]
    }
   ],
   "source": [
    "# Skip model loading if already in memory\n",
    "print(\"\\n✅ Using the Publishability Model already in memory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "executionInfo": {
     "elapsed": 104519,
     "status": "ok",
     "timestamp": 1736061654883,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "4ELFepUHTyqm",
    "outputId": "c6f07f0b-b65c-46cb-f617-fc1ca7bd89bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Publishability Transformer Model Found in Environment.\n",
      "\n",
      "📤 Upload the Test Dataset (CSV format with 'paper_id' and 'content' columns):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-cfa889c5-d60b-40d9-98f6-cd0b3c17cb7e\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-cfa889c5-d60b-40d9-98f6-cd0b3c17cb7e\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test_dataset.csv to test_dataset (7).csv\n",
      "\n",
      "✅ Test Dataset Loaded. Overview:\n",
      "  paper_id                                            content\n",
      "0  paper_1  Leveraging Clustering Techniques for Enhanced\\...\n",
      "1  paper_2  Virus Propagation and their Far-Reaching\\nImpl...\n",
      "2  paper_3  Explainable Reinforcement Learning for Financi...\n",
      "3  paper_4  Graph Neural Networks Without Training: Harnes...\n",
      "4  paper_5  Collaborative Clothing Segmentation and\\nIdent...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "<ipython-input-64-1df20881d476>:50: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  publishability_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚙️ Classifying Papers for Publishability...\n",
      "\n",
      "✅ Filtered Publishable Papers:\n",
      "  paper_id                                            content  publishable\n",
      "0  paper_1  leveraging clustering techniques for enhanced ...  Publishable\n",
      "2  paper_3  explainable reinforcement learning for financi...  Publishable\n",
      "3  paper_4  graph neural networks without training harness...  Publishable\n",
      "4  paper_5  collaborative clothing segmentation and identi...  Publishable\n",
      "6  paper_7  joint syntactodiscourse parsing and the syntac...  Publishable\n",
      "\n",
      "✅ Total Publishable Papers: 97\n",
      "\n",
      "✅ Publishable Test Dataset saved to: /content/publishable_test_dataset.csv\n",
      "\n",
      "📥 Click below to download the Publishable Test Dataset CSV:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_aed3a91c-6d65-4a10-8c33-f757233af229\", \"publishable_test_dataset.csv\", 1884402)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4.1: Reclassify Test Dataset for Publishability (With Model Upload Option)\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from google.colab import files\n",
    "import re\n",
    "import os\n",
    "\n",
    "# ✅ 1. Upload Publishability Transformer Model (if not available)\n",
    "model_path = '/content/publishability_transformer_model.pth'\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"\\n📤 Upload the Publishability Transformer Model (e.g., .pth file):\")\n",
    "    uploaded_model = files.upload()\n",
    "    model_file = list(uploaded_model.keys())[0]\n",
    "    model_path = f\"/content/{model_file}\"\n",
    "    print(f\"\\n✅ Model uploaded and saved as: {model_path}\")\n",
    "else:\n",
    "    print(\"\\n✅ Publishability Transformer Model Found in Environment.\")\n",
    "\n",
    "# ✅ 2. Upload Test Dataset\n",
    "print(\"\\n📤 Upload the Test Dataset (CSV format with 'paper_id' and 'content' columns):\")\n",
    "uploaded_test = files.upload()\n",
    "test_file = list(uploaded_test.keys())[0]\n",
    "test_path = f\"/content/{test_file}\"\n",
    "\n",
    "# ✅ 3. Load the Dataset\n",
    "df_test = pd.read_csv(test_path)\n",
    "print(\"\\n✅ Test Dataset Loaded. Overview:\")\n",
    "print(df_test.head())\n",
    "\n",
    "# ✅ 4. Verify Required Columns\n",
    "if 'content' not in df_test.columns or 'paper_id' not in df_test.columns:\n",
    "    raise ValueError(\"The dataset must have 'content' and 'paper_id' columns!\")\n",
    "\n",
    "# ✅ 5. Preprocess Text Data\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df_test['content'] = df_test['content'].apply(preprocess_text)\n",
    "\n",
    "# ✅ 6. Load Pretrained Publishability Model\n",
    "publishability_model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "publishability_model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "publishability_model.to(device)\n",
    "\n",
    "# ✅ 7. Load Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# ✅ 8. Classify Papers for Publishability\n",
    "def classify_publishability(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = publishability_model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    return 'Publishable' if prediction == 1 else 'Non-Publishable'\n",
    "\n",
    "print(\"\\n⚙️ Classifying Papers for Publishability...\")\n",
    "df_test['publishable'] = df_test['content'].apply(classify_publishability)\n",
    "\n",
    "# ✅ 9. Filter Only \"Publishable\" Papers\n",
    "df_publishable = df_test[df_test['publishable'] == 'Publishable'].copy()\n",
    "print(\"\\n✅ Filtered Publishable Papers:\")\n",
    "print(df_publishable.head())\n",
    "print(f\"\\n✅ Total Publishable Papers: {len(df_publishable)}\")\n",
    "\n",
    "# ✅ 10. Save Filtered Dataset\n",
    "publishable_test_path = '/content/publishable_test_dataset.csv'\n",
    "df_publishable[['paper_id', 'content']].to_csv(publishable_test_path, index=False)\n",
    "print(f\"\\n✅ Publishable Test Dataset saved to: {publishable_test_path}\")\n",
    "\n",
    "# ✅ 11. Enable Download\n",
    "print(\"\\n📥 Click below to download the Publishable Test Dataset CSV:\")\n",
    "files.download(publishable_test_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 787
    },
    "executionInfo": {
     "elapsed": 12938,
     "status": "ok",
     "timestamp": 1736061826913,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "QSVJDoLfVuyh",
    "outputId": "560d66be-b864-44c5-c833-f361b0e66d80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Using Filtered Publishable Papers Dataset from Previous Step:\n",
      "  paper_id                                            content  publishable  \\\n",
      "0  paper_1  leveraging clustering techniques for enhanced ...  Publishable   \n",
      "2  paper_3  explainable reinforcement learning for financi...  Publishable   \n",
      "3  paper_4  graph neural networks without training harness...  Publishable   \n",
      "4  paper_5  collaborative clothing segmentation and identi...  Publishable   \n",
      "6  paper_7  joint syntactodiscourse parsing and the syntac...  Publishable   \n",
      "\n",
      "  conference                                          rationale  \n",
      "0       TMLR  This paper aligns with the key themes and focu...  \n",
      "2    NeurIPS  This paper aligns with the key themes and focu...  \n",
      "3    NeurIPS  This paper aligns with the key themes and focu...  \n",
      "4       CVPR  This paper aligns with the key themes and focu...  \n",
      "6      EMNLP  This paper aligns with the key themes and focu...  \n",
      "\n",
      "✅ Total Publishable Papers: 97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "<ipython-input-66-d12f38c8ed51>:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚙️ Classifying Papers and Generating Rationales...\n",
      "\n",
      "✅ Sample Classified Papers with Rationales:\n",
      "  paper_id                                            content  publishable  \\\n",
      "0  paper_1  leveraging clustering techniques for enhanced ...  Publishable   \n",
      "2  paper_3  explainable reinforcement learning for financi...  Publishable   \n",
      "3  paper_4  graph neural networks without training harness...  Publishable   \n",
      "4  paper_5  collaborative clothing segmentation and identi...  Publishable   \n",
      "6  paper_7  joint syntactodiscourse parsing and the syntac...  Publishable   \n",
      "\n",
      "  conference                                          rationale  \n",
      "0       TMLR  This paper aligns with the key themes and focu...  \n",
      "2    NeurIPS  This paper aligns with the key themes and focu...  \n",
      "3    NeurIPS  This paper aligns with the key themes and focu...  \n",
      "4       CVPR  This paper aligns with the key themes and focu...  \n",
      "6      EMNLP  This paper aligns with the key themes and focu...  \n",
      "\n",
      "✅ Final classification results saved to: /content/publishable_conference_classification_results.csv\n",
      "\n",
      "📥 Click below to download the final classification results CSV:\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_1b75723e-d5b9-4f6b-8a38-4c60f86010be\", \"publishable_conference_classification_results.csv\", 1899194)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4.2: Classify Publishable Papers into Conferences\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from google.colab import files\n",
    "\n",
    "# ✅ 1. Verify the Publishable Dataset from Previous Step\n",
    "print(\"\\n✅ Using Filtered Publishable Papers Dataset from Previous Step:\")\n",
    "print(df_publishable.head())\n",
    "\n",
    "# ✅ 2. Ensure Required Columns Exist\n",
    "if 'content' not in df_publishable.columns or 'paper_id' not in df_publishable.columns:\n",
    "    raise ValueError(\"The dataset must have 'content' and 'paper_id' columns!\")\n",
    "\n",
    "print(f\"\\n✅ Total Publishable Papers: {len(df_publishable)}\")\n",
    "\n",
    "# ✅ 3. Preprocess Text Data\n",
    "def preprocess_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "df_publishable['content'] = df_publishable['content'].apply(preprocess_text)\n",
    "\n",
    "# ✅ 4. Load Fine-Tuned Conference Classification Model\n",
    "model_path = '/content/conference_classification_model.pth'\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=5)\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# ✅ 5. Load Tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# ✅ 6. Load Label Encoder for Conference Classes\n",
    "conference_classes = ['TMLR', 'NeurIPS', 'KDD', 'EMNLP', 'CVPR']\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(conference_classes)\n",
    "\n",
    "# ✅ 7. Classify Papers and Generate Rationales\n",
    "def classify_paper(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding='max_length', max_length=512)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
    "    predicted_conference = label_encoder.inverse_transform([prediction])[0]\n",
    "    return predicted_conference\n",
    "\n",
    "def generate_rationale(text, conference):\n",
    "    return f\"This paper aligns with the key themes and focus areas of {conference}, making it an appropriate venue for submission based on its content and findings.\"\n",
    "\n",
    "print(\"\\n⚙️ Classifying Papers and Generating Rationales...\")\n",
    "df_publishable['conference'] = df_publishable['content'].apply(classify_paper)\n",
    "df_publishable['rationale'] = df_publishable.apply(\n",
    "    lambda row: generate_rationale(row['content'], row['conference']), axis=1\n",
    ")\n",
    "\n",
    "# ✅ 8. Display Sample Results\n",
    "print(\"\\n✅ Sample Classified Papers with Rationales:\")\n",
    "print(df_publishable.head())\n",
    "\n",
    "# ✅ 9. Save Final Results\n",
    "final_results_path = '/content/publishable_conference_classification_results.csv'\n",
    "df_publishable[['paper_id', 'content', 'conference', 'rationale']].to_csv(final_results_path, index=False)\n",
    "print(f\"\\n✅ Final classification results saved to: {final_results_path}\")\n",
    "\n",
    "# ✅ 10. Enable Download\n",
    "print(\"\\n📥 Click below to download the final classification results CSV:\")\n",
    "files.download(final_results_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "91b2587566d241cdbd959a00df345745",
      "8bbe11ea6b54487ebb5afd2d9e85b05f",
      "d7fabd8891ed44cbbf89a8cb72ff957c",
      "70ae794f51ce42b2b4a425d860574845",
      "d92e3ceab0bf4191aaee354b147b3a0d",
      "74b0e12ea7de45108298ad025bff4a78",
      "4b6fbba68eee4bb691f30680035b7cfd",
      "c5536723e7d54bf58d13a3274a419dff",
      "c954656829b14380acb95895d38fe39c",
      "c20143fa8ead4b4989775a4b57805de3",
      "83c1a575f178446d9538dbdbee84dacb",
      "40c4c93bd80644848b2c33988e909c14",
      "cbdf620d49b74a0597da07daf660c9c5",
      "c7dc85b9f2f54a8ab6ab249e230f5ce5",
      "72c662f407b145fc8b066c698481ea51",
      "6bb89d0e603948bba5f5f4760262a5c8",
      "4823b6d0bac24eaf9b9637407bcc3db6",
      "20323aff6c6445419b262aec823672fc",
      "ff3de39d7b9c4fc6823f7e850ae4695b",
      "b607d0ace2ef412c9215289ebb32ad8c",
      "33eddb217f864eccb695bb5461bc298d",
      "207b4dcfa9c149ab99cef02ad9780828",
      "1c01542d9947454b8b489e8f956a072f",
      "0940fc9314c8442aa03c7bac5a869caa",
      "56fc5e33b8d747d99809fd19bf8d1f99",
      "ae4e355ad3b643b5aad2ba950d754696",
      "a0172caa429644ae8ef9aa2895da9ea8",
      "045d8b5a37344a6aac89f8b0c0a39717",
      "8a9c29c9914d41c292835fba2ef149eb",
      "dccbeb3bb77c415584222c60d93e018b",
      "6b4fbfee6ab441ab840ee1d273b62780",
      "202c2e854c4e430281a247c25acc3d4e",
      "e029558bcaeb4c4f9cb227f3ffb6361e",
      "d5e9ea75e96d49718f885c477448378a",
      "a60aa281b8004b4090d4e88892579212",
      "1415d7b798e7407385c273a5bc9d1e3b",
      "d30b7abe2f6347b6a506cc9dd27274ae",
      "c0a5733828264bf4b1fd843b5270be6c",
      "ea2426e0a021472199222b3c8e48060e",
      "2ad722205dbe491fb0abc6e593de329e",
      "fe8905396ed54f789af02379cef1cef8",
      "af15d2ffe4af4c6d98536d1941c82738",
      "629023bb83ab4dcebb0add947fb8b3b7",
      "c024207ba4a24bacb49bb0900317959e",
      "3badd6c7583f40f6a5e1daad3b32b20c",
      "e5b78109ba9448fdbf2b7a6aae13bafe",
      "d0a7a624367c49038fd6490a81e69475",
      "b6a2f8f833394d018b2d196f00985ced",
      "361c918995c2449386c175122ced729f",
      "b7a5fec8ed0740f3862fee87e52e6041",
      "8ade0dfa2abf4c5b84d6d95e5bc9f251",
      "98ea1b140dd2435d8beee90893f054c1",
      "80f2c656e6f24d13900765729e472ba4",
      "440ea0049d9f4d41b17075a3f6a429c5",
      "44ebeb06e350433f98423eb353500d1c"
     ]
    },
    "executionInfo": {
     "elapsed": 87489,
     "status": "error",
     "timestamp": 1736441688540,
     "user": {
      "displayName": "Vishesh Gupta",
      "userId": "01335267842791147159"
     },
     "user_tz": -330
    },
    "id": "ofXA09Nr-5Is",
    "outputId": "611a7c94-96c2-4ac0-806f-b4df3c8c84e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pathway\n",
      "  Downloading pathway-0.16.4-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp>=3.8.4 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.11.11)\n",
      "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (8.1.8)\n",
      "Requirement already satisfied: geopy>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.4.1)\n",
      "Collecting h3>=4 (from pathway)\n",
      "  Downloading h3-4.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.26.4)\n",
      "Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.6.0)\n",
      "Requirement already satisfied: shapely>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.0.6)\n",
      "Collecting sqlglot==10.6.1 (from pathway)\n",
      "  Downloading sqlglot-10.6.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pyarrow>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (17.0.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.32.3)\n",
      "Collecting python-sat>=0.1.8.dev0 (from pathway)\n",
      "  Downloading python_sat-1.8.dev14-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting beartype<0.16.0,>=0.14.0 (from pathway)\n",
      "  Downloading beartype-0.15.0-py3-none-any.whl.metadata (28 kB)\n",
      "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (13.9.4)\n",
      "Collecting diskcache>=5.2.1 (from pathway)\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.1.3 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.2.2)\n",
      "Collecting boto3>=1.26.76 (from pathway)\n",
      "  Downloading boto3-1.35.95-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-api-python-client>=2.108.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.155.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (4.12.2)\n",
      "Requirement already satisfied: panel>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.5.5)\n",
      "Collecting jupyter-bokeh>=3.0.7 (from pathway)\n",
      "  Downloading jupyter_bokeh-4.0.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jmespath>=1.0.1 (from pathway)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting aiohttp-cors>=0.7.0 (from pathway)\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from pathway) (1.29.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.22.0 (from pathway)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting fs>=2.4.16 (from pathway)\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting async-lru>=2.0.4 (from pathway)\n",
      "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: networkx>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.4.2)\n",
      "Requirement already satisfied: google-cloud-pubsub>=2.21.1 in /usr/local/lib/python3.10/dist-packages (from pathway) (2.27.1)\n",
      "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.10/dist-packages (from pathway) (3.25.0)\n",
      "Collecting pydantic~=2.9.0 (from pathway)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: gitpython>=3.1.43 in /usr/local/lib/python3.10/dist-packages (from pathway) (3.1.44)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->pathway) (1.18.3)\n",
      "Collecting botocore<1.36.0,>=1.35.95 (from boto3>=1.26.76->pathway)\n",
      "  Downloading botocore-1.35.95-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.26.76->pathway)\n",
      "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting appdirs~=1.4.3 (from fs>=2.4.16->pathway)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (75.1.0)\n",
      "Requirement already satisfied: six~=1.10 in /usr/local/lib/python3.10/dist-packages (from fs>=2.4.16->pathway) (1.17.0)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.10/dist-packages (from geopy>=2.4.0->pathway) (2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.43->pathway) (4.0.12)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.22.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.27.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (0.2.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (2.19.2)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=2.108.0->pathway) (4.1.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.51.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.69.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.25.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (4.25.5)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (0.14.0)\n",
      "Requirement already satisfied: grpcio-status>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-pubsub>=2.21.1->pathway) (1.62.3)\n",
      "Requirement already satisfied: bokeh==3.* in /usr/local/lib/python3.10/dist-packages (from jupyter-bokeh>=3.0.7->pathway) (3.6.2)\n",
      "Collecting ipywidgets==8.* (from jupyter-bokeh>=3.0.7->pathway)\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.1.5)\n",
      "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (1.3.1)\n",
      "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (24.2)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (11.1.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.0.2)\n",
      "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (6.3.3)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (2024.9.0)\n",
      "Collecting comm>=0.1.3 (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway)\n",
      "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (7.34.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (5.7.1)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway)\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.13)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (1.2.15)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.22.0->pathway) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway) (1.66.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.22.0->pathway)\n",
      "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 (from google-cloud-pubsub>=2.21.1->pathway)\n",
      "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk>=1.22.0->pathway) (0.50b0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1->pathway) (2024.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (6.2.0)\n",
      "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.0.3)\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.7)\n",
      "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.0)\n",
      "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (0.4.2)\n",
      "Requirement already satisfied: param<3.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (2.2.0)\n",
      "Requirement already satisfied: pyviz-comms>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (3.0.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from panel>=1.3.1->pathway) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic~=2.9.0->pathway) (0.7.0)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic~=2.9.0->pathway)\n",
      "  Downloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->pathway) (2024.12.14)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->pathway) (2.18.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->pathway) (3.5.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-bigquery->pathway) (2.7.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api>=1.22.0->pathway) (1.17.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.43->pathway) (5.0.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (4.9)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery->pathway) (1.6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client>=2.108.0->pathway) (3.2.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.22.0->pathway) (3.21.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.3.1->pathway) (0.1.2)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.3.1->pathway) (0.5.1)\n",
      "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.3.1->pathway) (1.0.3)\n",
      "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway)\n",
      "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.4.2)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (3.0.48)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (4.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh==3.*->jupyter-bokeh>=3.0.7->pathway) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=2.108.0->pathway) (0.6.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets==8.*->jupyter-bokeh>=3.0.7->pathway) (0.2.13)\n",
      "Downloading pathway-0.16.4-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sqlglot-10.6.1-py3-none-any.whl (223 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
      "Downloading beartype-0.15.0-py3-none-any.whl (777 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m777.6/777.6 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.35.95-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h3-4.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading jupyter_bokeh-4.0.5-py3-none-any.whl (148 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.23.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_sat-1.8.dev14-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_28_x86_64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading botocore-1.35.95-py3-none-any.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sqlglot, appdirs, widgetsnbextension, python-sat, pydantic-core, protobuf, jmespath, jedi, h3, fs, diskcache, comm, beartype, async-lru, pydantic, opentelemetry-proto, botocore, s3transfer, opentelemetry-exporter-otlp-proto-common, ipywidgets, jupyter-bokeh, boto3, aiohttp-cors, opentelemetry-exporter-otlp-proto-grpc, pathway\n",
      "  Attempting uninstall: sqlglot\n",
      "    Found existing installation: sqlglot 25.1.0\n",
      "    Uninstalling sqlglot-25.1.0:\n",
      "      Successfully uninstalled sqlglot-25.1.0\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 3.6.10\n",
      "    Uninstalling widgetsnbextension-3.6.10:\n",
      "      Successfully uninstalled widgetsnbextension-3.6.10\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.27.2\n",
      "    Uninstalling pydantic_core-2.27.2:\n",
      "      Successfully uninstalled pydantic_core-2.27.2\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.25.5\n",
      "    Uninstalling protobuf-4.25.5:\n",
      "      Successfully uninstalled protobuf-4.25.5\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.10.4\n",
      "    Uninstalling pydantic-2.10.4:\n",
      "      Successfully uninstalled pydantic-2.10.4\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 7.7.1\n",
      "    Uninstalling ipywidgets-7.7.1:\n",
      "      Successfully uninstalled ipywidgets-7.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 1.30.0 requires sqlglot<25.2,>=23.6.3, but you have sqlglot 10.6.1 which is incompatible.\n",
      "ibis-framework 9.2.0 requires sqlglot<25.7,>=23.4, but you have sqlglot 10.6.1 which is incompatible.\n",
      "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\n",
      "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohttp-cors-0.7.0 appdirs-1.4.4 async-lru-2.0.4 beartype-0.15.0 boto3-1.35.95 botocore-1.35.95 comm-0.2.2 diskcache-5.6.3 fs-2.4.16 h3-4.1.2 ipywidgets-8.1.5 jedi-0.19.2 jmespath-1.0.1 jupyter-bokeh-4.0.5 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-proto-1.29.0 pathway-0.16.4 protobuf-5.29.3 pydantic-2.9.2 pydantic-core-2.23.4 python-sat-1.8.dev14 s3transfer-0.10.4 sqlglot-10.6.1 widgetsnbextension-4.0.13\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "  const py_version = '3.6.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  const reloading = false;\n",
       "  const Bokeh = root.Bokeh;\n",
       "\n",
       "  // Set a timeout for this load but only if we are not already initializing\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      // Don't load bokeh if it is still initializing\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      // There is nothing to load\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error(e) {\n",
       "      const src_el = e.srcElement\n",
       "      console.error(\"failed to load \" + (src_el.href || src_el.src));\n",
       "    }\n",
       "\n",
       "    const skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@6.3.0/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min'}, 'shim': {}});\n",
       "      require([\"tabulator\"], function(Tabulator) {\n",
       "        window.Tabulator = Tabulator\n",
       "        on_load()\n",
       "      })\n",
       "      require([\"moment\"], function(moment) {\n",
       "        window.moment = moment\n",
       "        on_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 2;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    const existing_stylesheets = []\n",
       "    const links = document.getElementsByTagName('link')\n",
       "    for (let i = 0; i < links.length; i++) {\n",
       "      const link = links[i]\n",
       "      if (link.href != null) {\n",
       "        existing_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (existing_stylesheets.indexOf(escaped) !== -1) {\n",
       "        on_load()\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window.Tabulator !== undefined) && (!(window.Tabulator instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/js/tabulator.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(encodeURI(urls[i]))\n",
       "      }\n",
       "    }    if (((window.moment !== undefined) && (!(window.moment instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(encodeURI(urls[i]))\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    const scripts = document.getElementsByTagName('script')\n",
       "    for (let i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "        existing_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (let i = 0; i < js_modules.length; i++) {\n",
       "      const url = js_modules[i];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      const url = js_exports[name];\n",
       "      const escaped = encodeURI(url)\n",
       "      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n",
       "        if (!window.requirejs) {\n",
       "          on_load();\n",
       "        }\n",
       "        continue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/panel.min.js\"];\n",
       "  const js_modules = [];\n",
       "  const js_exports = {};\n",
       "  const css_urls = [\"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/css/tabulator_simple.min.css?v=1.5.5\"];\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (let i = 0; i < inline_js.length; i++) {\n",
       "        try {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "        } catch(e) {\n",
       "          if (!reloading) {\n",
       "            throw e;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "        var NewBokeh = root.Bokeh;\n",
       "        if (Bokeh.versions === undefined) {\n",
       "          Bokeh.versions = new Map();\n",
       "        }\n",
       "        if (NewBokeh.version !== Bokeh.version) {\n",
       "          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "        }\n",
       "        root.Bokeh = Bokeh;\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      // If the timeout and bokeh was not successfully loaded we reset\n",
       "      // everything and try loading again\n",
       "      root._bokeh_timeout = Date.now() + 5000;\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      root._bokeh_is_loading = 0\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "        if (root.Bokeh) {\n",
       "          root.Bokeh = undefined;\n",
       "        }\n",
       "        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "        run_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.6.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@6.3.0/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min'}, 'shim': {}});\n      require([\"tabulator\"], function(Tabulator) {\n        window.Tabulator = Tabulator\n        on_load()\n      })\n      require([\"moment\"], function(moment) {\n        window.moment = moment\n        on_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 2;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window.Tabulator !== undefined) && (!(window.Tabulator instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/js/tabulator.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    if (((window.moment !== undefined) && (!(window.moment instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(encodeURI(urls[i]))\n      }\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.6.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.6.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.5/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [\"https://cdn.holoviz.org/panel/1.5.5/dist/bundled/datatabulator/tabulator-tables@6.3.0/dist/css/tabulator_simple.min.css?v=1.5.5\"];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='ba9e1b5b-faec-4e8e-9fbb-132c14c8d4cf'>\n",
       "  <div id=\"e57f8f7b-e487-4ade-8870-707f860d9567\" data-root-id=\"ba9e1b5b-faec-4e8e-9fbb-132c14c8d4cf\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"3914050b-4a48-4ca5-9c86-70c5c68f9197\":{\"version\":\"3.6.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"ba9e1b5b-faec-4e8e-9fbb-132c14c8d4cf\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"e8d29dda-ff96-479b-b5d8-fed86dfc1103\",\"attributes\":{\"plot_id\":\"ba9e1b5b-faec-4e8e-9fbb-132c14c8d4cf\",\"comm_id\":\"70d985ca362a48cbb3028af670c02364\",\"client_comm_id\":\"f0eeca82bd3e4abca550fe1c0cd51c68\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"3914050b-4a48-4ca5-9c86-70c5c68f9197\",\"roots\":{\"ba9e1b5b-faec-4e8e-9fbb-132c14c8d4cf\":\"e57f8f7b-e487-4ade-8870-707f860d9567\"},\"root_ids\":[\"ba9e1b5b-faec-4e8e-9fbb-132c14c8d4cf\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root.Tabulator !== undefined) && ( root.Tabulator !== undefined))\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b2587566d241cdbd959a00df345745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c4c93bd80644848b2c33988e909c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c01542d9947454b8b489e8f956a072f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e9ea75e96d49718f885c477448378a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3badd6c7583f40f6a5e1daad3b32b20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "<ipython-input-1-f8d17bbf8110>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(publishability_model_path, map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/path/to/publishability_model.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f8d17bbf8110>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublishability_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1317\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1319\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/publishability_model.pth'"
     ]
    }
   ],
   "source": [
    "# Install Pathway (if not installed)\n",
    "!pip install pathway\n",
    "\n",
    "# Import Libraries\n",
    "import pathway as pw\n",
    "from pathway.xpacks.llm.vector_store import VectorStoreServer, VectorStoreClient\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# === Step 1: Load Dataset with Pathway Connectors ===\n",
    "# Stream dataset from Google Drive (or replace with your source)\n",
    "docs = pw.io.fs.read(\n",
    "    \"gdrive://path/to/your/dataset\",\n",
    "    format=\"binary\",\n",
    "    mode=\"streaming\",\n",
    "    with_metadata=True\n",
    ")\n",
    "\n",
    "# === Step 2: Define Embedding Function ===\n",
    "# Load your publishability Transformer model\n",
    "publishability_model_path = \"/path/to/publishability_model.pth\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.load_state_dict(torch.load(publishability_model_path, map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "def embed_paper(text):\n",
    "    \"\"\"Generate embeddings using the Transformer model.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().tolist()\n",
    "\n",
    "# === Step 3: Set Up Pathway VectorStore Server ===\n",
    "server = VectorStoreServer(\n",
    "    docs,\n",
    "    embedder=embed_paper,\n",
    "    parser=pw.xpacks.llm.parsers.ParseUtf8()\n",
    ")\n",
    "server.run_server(host=\"0.0.0.0\", port=8000, threaded=True)\n",
    "\n",
    "# === Step 4: Classify Papers for Publishability ===\n",
    "def classify_paper_for_publishability(text):\n",
    "    \"\"\"Classify paper as Publishable or Non-Publishable.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return \"Publishable\" if torch.argmax(outputs.logits) == 1 else \"Non-Publishable\"\n",
    "\n",
    "# === Step 5: Use VectorStore for Conference Selection ===\n",
    "# Load Conference Classification Model\n",
    "conference_model_path = \"/path/to/conference_model.pth\"\n",
    "conference_model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)\n",
    "conference_model.load_state_dict(torch.load(conference_model_path, map_location=torch.device('cpu')))\n",
    "conference_model.eval()\n",
    "\n",
    "conference_classes = ['TMLR', 'NeurIPS', 'KDD', 'EMNLP', 'CVPR']\n",
    "\n",
    "def classify_conference(text):\n",
    "    \"\"\"Classify paper into a conference.\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = conference_model(**inputs)\n",
    "    return conference_classes[torch.argmax(outputs.logits)]\n",
    "\n",
    "# === Step 6: Query Pathway VectorStore and Generate Results ===\n",
    "client = VectorStoreClient(host=\"localhost\", port=8000)\n",
    "retrieved_docs = client.query(query=\"Relevant research paper content\", k=5)\n",
    "\n",
    "results = []\n",
    "for doc in retrieved_docs:\n",
    "    paper_content = doc['text']\n",
    "    publishability = classify_paper_for_publishability(paper_content)\n",
    "    if publishability == \"Publishable\":\n",
    "        conference = classify_conference(paper_content)\n",
    "        rationale = f\"This paper aligns with the key themes and focus areas of {conference}.\"\n",
    "        results.append({\n",
    "            \"paper_id\": doc['metadata']['paper_id'],\n",
    "            \"content\": paper_content,\n",
    "            \"conference\": conference,\n",
    "            \"rationale\": rationale\n",
    "        })\n",
    "\n",
    "# === Step 7: Save Results to CSV ===\n",
    "results_df = pd.DataFrame(results)\n",
    "results_path = \"/content/publishable_conference_results.csv\"\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\"Results saved to: {results_path}\")\n",
    "\n",
    "\n",
    "# Example: Pathway connectors can replace manual file loading for dynamic streaming.\n",
    "# Uncomment and adjust the following block for live streaming data:\n",
    "# import pathway as pw\n",
    "# docs_publishable = pw.io.fs.read(\n",
    "#     '/kaggle/input/publishable/', format='binary', mode='static', with_metadata=True)\n",
    "# docs_non_publishable = pw.io.fs.read(\n",
    "#     '/kaggle/input/non-publishable/', format='binary', mode='static', with_metadata=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO1OfEXCsEq0oKWWRFarWIt",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "045d8b5a37344a6aac89f8b0c0a39717": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0940fc9314c8442aa03c7bac5a869caa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_045d8b5a37344a6aac89f8b0c0a39717",
      "placeholder": "​",
      "style": "IPY_MODEL_8a9c29c9914d41c292835fba2ef149eb",
      "tabbable": null,
      "tooltip": null,
      "value": "tokenizer.json: 100%"
     }
    },
    "1415d7b798e7407385c273a5bc9d1e3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_fe8905396ed54f789af02379cef1cef8",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_af15d2ffe4af4c6d98536d1941c82738",
      "tabbable": null,
      "tooltip": null,
      "value": 570
     }
    },
    "1c01542d9947454b8b489e8f956a072f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0940fc9314c8442aa03c7bac5a869caa",
       "IPY_MODEL_56fc5e33b8d747d99809fd19bf8d1f99",
       "IPY_MODEL_ae4e355ad3b643b5aad2ba950d754696"
      ],
      "layout": "IPY_MODEL_a0172caa429644ae8ef9aa2895da9ea8",
      "tabbable": null,
      "tooltip": null
     }
    },
    "202c2e854c4e430281a247c25acc3d4e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "20323aff6c6445419b262aec823672fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "207b4dcfa9c149ab99cef02ad9780828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "2ad722205dbe491fb0abc6e593de329e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "33eddb217f864eccb695bb5461bc298d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "361c918995c2449386c175122ced729f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3badd6c7583f40f6a5e1daad3b32b20c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e5b78109ba9448fdbf2b7a6aae13bafe",
       "IPY_MODEL_d0a7a624367c49038fd6490a81e69475",
       "IPY_MODEL_b6a2f8f833394d018b2d196f00985ced"
      ],
      "layout": "IPY_MODEL_361c918995c2449386c175122ced729f",
      "tabbable": null,
      "tooltip": null
     }
    },
    "40c4c93bd80644848b2c33988e909c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cbdf620d49b74a0597da07daf660c9c5",
       "IPY_MODEL_c7dc85b9f2f54a8ab6ab249e230f5ce5",
       "IPY_MODEL_72c662f407b145fc8b066c698481ea51"
      ],
      "layout": "IPY_MODEL_6bb89d0e603948bba5f5f4760262a5c8",
      "tabbable": null,
      "tooltip": null
     }
    },
    "440ea0049d9f4d41b17075a3f6a429c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44ebeb06e350433f98423eb353500d1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "4823b6d0bac24eaf9b9637407bcc3db6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b6fbba68eee4bb691f30680035b7cfd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "56fc5e33b8d747d99809fd19bf8d1f99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_dccbeb3bb77c415584222c60d93e018b",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6b4fbfee6ab441ab840ee1d273b62780",
      "tabbable": null,
      "tooltip": null,
      "value": 466062
     }
    },
    "629023bb83ab4dcebb0add947fb8b3b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b4fbfee6ab441ab840ee1d273b62780": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6bb89d0e603948bba5f5f4760262a5c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70ae794f51ce42b2b4a425d860574845": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_c20143fa8ead4b4989775a4b57805de3",
      "placeholder": "​",
      "style": "IPY_MODEL_83c1a575f178446d9538dbdbee84dacb",
      "tabbable": null,
      "tooltip": null,
      "value": " 48.0/48.0 [00:00&lt;00:00, 3.52kB/s]"
     }
    },
    "72c662f407b145fc8b066c698481ea51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_33eddb217f864eccb695bb5461bc298d",
      "placeholder": "​",
      "style": "IPY_MODEL_207b4dcfa9c149ab99cef02ad9780828",
      "tabbable": null,
      "tooltip": null,
      "value": " 232k/232k [00:00&lt;00:00, 1.83MB/s]"
     }
    },
    "74b0e12ea7de45108298ad025bff4a78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80f2c656e6f24d13900765729e472ba4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "83c1a575f178446d9538dbdbee84dacb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "8a9c29c9914d41c292835fba2ef149eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "8ade0dfa2abf4c5b84d6d95e5bc9f251": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "8bbe11ea6b54487ebb5afd2d9e85b05f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_74b0e12ea7de45108298ad025bff4a78",
      "placeholder": "​",
      "style": "IPY_MODEL_4b6fbba68eee4bb691f30680035b7cfd",
      "tabbable": null,
      "tooltip": null,
      "value": "tokenizer_config.json: 100%"
     }
    },
    "91b2587566d241cdbd959a00df345745": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8bbe11ea6b54487ebb5afd2d9e85b05f",
       "IPY_MODEL_d7fabd8891ed44cbbf89a8cb72ff957c",
       "IPY_MODEL_70ae794f51ce42b2b4a425d860574845"
      ],
      "layout": "IPY_MODEL_d92e3ceab0bf4191aaee354b147b3a0d",
      "tabbable": null,
      "tooltip": null
     }
    },
    "98ea1b140dd2435d8beee90893f054c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a0172caa429644ae8ef9aa2895da9ea8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a60aa281b8004b4090d4e88892579212": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_ea2426e0a021472199222b3c8e48060e",
      "placeholder": "​",
      "style": "IPY_MODEL_2ad722205dbe491fb0abc6e593de329e",
      "tabbable": null,
      "tooltip": null,
      "value": "config.json: 100%"
     }
    },
    "ae4e355ad3b643b5aad2ba950d754696": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_202c2e854c4e430281a247c25acc3d4e",
      "placeholder": "​",
      "style": "IPY_MODEL_e029558bcaeb4c4f9cb227f3ffb6361e",
      "tabbable": null,
      "tooltip": null,
      "value": " 466k/466k [00:00&lt;00:00, 3.75MB/s]"
     }
    },
    "af15d2ffe4af4c6d98536d1941c82738": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b607d0ace2ef412c9215289ebb32ad8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b6a2f8f833394d018b2d196f00985ced": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_440ea0049d9f4d41b17075a3f6a429c5",
      "placeholder": "​",
      "style": "IPY_MODEL_44ebeb06e350433f98423eb353500d1c",
      "tabbable": null,
      "tooltip": null,
      "value": " 440M/440M [00:02&lt;00:00, 206MB/s]"
     }
    },
    "b7a5fec8ed0740f3862fee87e52e6041": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c024207ba4a24bacb49bb0900317959e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "c0a5733828264bf4b1fd843b5270be6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c20143fa8ead4b4989775a4b57805de3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5536723e7d54bf58d13a3274a419dff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c7dc85b9f2f54a8ab6ab249e230f5ce5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_ff3de39d7b9c4fc6823f7e850ae4695b",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b607d0ace2ef412c9215289ebb32ad8c",
      "tabbable": null,
      "tooltip": null,
      "value": 231508
     }
    },
    "c954656829b14380acb95895d38fe39c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cbdf620d49b74a0597da07daf660c9c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_4823b6d0bac24eaf9b9637407bcc3db6",
      "placeholder": "​",
      "style": "IPY_MODEL_20323aff6c6445419b262aec823672fc",
      "tabbable": null,
      "tooltip": null,
      "value": "vocab.txt: 100%"
     }
    },
    "d0a7a624367c49038fd6490a81e69475": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_98ea1b140dd2435d8beee90893f054c1",
      "max": 440449768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_80f2c656e6f24d13900765729e472ba4",
      "tabbable": null,
      "tooltip": null,
      "value": 440449768
     }
    },
    "d30b7abe2f6347b6a506cc9dd27274ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_629023bb83ab4dcebb0add947fb8b3b7",
      "placeholder": "​",
      "style": "IPY_MODEL_c024207ba4a24bacb49bb0900317959e",
      "tabbable": null,
      "tooltip": null,
      "value": " 570/570 [00:00&lt;00:00, 40.3kB/s]"
     }
    },
    "d5e9ea75e96d49718f885c477448378a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a60aa281b8004b4090d4e88892579212",
       "IPY_MODEL_1415d7b798e7407385c273a5bc9d1e3b",
       "IPY_MODEL_d30b7abe2f6347b6a506cc9dd27274ae"
      ],
      "layout": "IPY_MODEL_c0a5733828264bf4b1fd843b5270be6c",
      "tabbable": null,
      "tooltip": null
     }
    },
    "d7fabd8891ed44cbbf89a8cb72ff957c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_c5536723e7d54bf58d13a3274a419dff",
      "max": 48,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c954656829b14380acb95895d38fe39c",
      "tabbable": null,
      "tooltip": null,
      "value": 48
     }
    },
    "d92e3ceab0bf4191aaee354b147b3a0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dccbeb3bb77c415584222c60d93e018b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e029558bcaeb4c4f9cb227f3ffb6361e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "StyleView",
      "background": null,
      "description_width": "",
      "font_size": null,
      "text_color": null
     }
    },
    "e5b78109ba9448fdbf2b7a6aae13bafe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "2.0.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "2.0.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "2.0.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_allow_html": false,
      "layout": "IPY_MODEL_b7a5fec8ed0740f3862fee87e52e6041",
      "placeholder": "​",
      "style": "IPY_MODEL_8ade0dfa2abf4c5b84d6d95e5bc9f251",
      "tabbable": null,
      "tooltip": null,
      "value": "model.safetensors: 100%"
     }
    },
    "ea2426e0a021472199222b3c8e48060e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe8905396ed54f789af02379cef1cef8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff3de39d7b9c4fc6823f7e850ae4695b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "2.0.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "2.0.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "2.0.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border_bottom": null,
      "border_left": null,
      "border_right": null,
      "border_top": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
